{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 87198,
     "status": "ok",
     "timestamp": 1593147077598,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "CwfA47wzHi1X",
    "outputId": "492c3f3f-03dd-4a77-ac38-a6ef388eeb0e",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.impute import SimpleImputer\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from tensorflow import nn ## de goi cac active function\n",
    "from sklearn import tree\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Input,Activation, Dropout, Flatten, Dense\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from collections import namedtuple\n",
    "import matplotlib\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import load_model\n",
    "from IPython.display import clear_output\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import np_utils ## dung de categorical cac label\n",
    "from sklearn.model_selection import train_test_split  ## dung de tach bo test ra\n",
    "from sklearn.datasets import load_iris\n",
    "import time\n",
    "import datetime\n",
    "from math import pow\n",
    "import random\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from collections import deque\n",
    "import csv\n",
    "from keras.layers import PReLU\n",
    "import math\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import h5py\n",
    "import simplejson as json\n",
    "from tqdm import tqdm\n",
    "from keras_radam import RAdam\n",
    "from sklearn import preprocessing\n",
    "from IPython.display import clear_output\n",
    "from keras.utils import  to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import math\n",
    "from keras.callbacks import History \n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.models import model_from_json\n",
    "from tensorflow.compat.v1.keras.optimizers import Adam\n",
    "import glob\n",
    "from keras.layers import LeakyReLU\n",
    "from mpi_adam import MpiAdam\n",
    "import tf_util as U\n",
    "from agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 15)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maze=[]\n",
    "def get_map():\n",
    "    maze=[]\n",
    "#     for i in range(30):\n",
    "#         if (i==0 or i==5 or i==6 or i==11 or i==12 or i==17 or i==18 or i == 23 or i== 24 or i==29 or i == 30):\n",
    "#               maze.append([0,1,1,1,1,0,0,1,1,1,1,0,0,1,1,1,1,0,0,1,1,1,1,0,0,1,1,1,1,0])\n",
    "#         elif (i==2 or i==8 or i==14 or i == 20 or i==26 ) :\n",
    "#               maze.append([1,0.9,0.95,0.9,0.9,1,1,0.9,0.95,0.9,0.9,1,1,0.9,0.95,0.9,0.9,1,1,0.9,0.95,0.9,0.9,1,1,0.9,0.95,0.9,0.9,1])\n",
    "#         else : \n",
    "#               maze.append([1,0.9,0.9,0.9,0.9,1,1,0.9,0.9,0.9,0.9,1,1,0.9,0.9,0.9,0.9,1,1,0.9,0.9,0.9,0.9,1,1,0.9,0.9,0.9,0.9,1])\n",
    "#     maze = np.asarray(maze)\n",
    "# 36x36 official\n",
    "#     for i in range(35):\n",
    "#         if (i==0 or i==4 or i==5 or i==9 or i==10 or i==14 or i==15 or i==19 or i==20 or i==24 or i==25 or i==29 or i==30 or i==34 or i==35):\n",
    "#             maze.append([0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0])\n",
    "#         elif (i==2 or i==7 or i==12 or i==17 or i==22 or i==27 or i==32) :\n",
    "#             maze.append([1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1])\n",
    "#         else : \n",
    "#             maze.append([1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1])\n",
    "#     maze = np.asarray(maze)\n",
    "#     return maze\n",
    "#8x8 official\n",
    "    for i in range(15):\n",
    "        if (i==0 or i==4 or i==5 or i==9 or i==10 or i==14 or i==15):\n",
    "            maze.append([0,1,1,1,0,0,1,1,1,0,0,1,1,1,0])\n",
    "        elif (i==2 or i==7 or i==12) :\n",
    "            maze.append([1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1])\n",
    "        else : \n",
    "            maze.append([1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1])\n",
    "    maze = np.asarray(maze)\n",
    "    return maze\n",
    "# for i in range(35):\n",
    "#     if (i==0 or i==4 or i==5 or i==9 or i==10 or i==14 or i==15 or i==19 or i==20 or i==24 or i==25 or i==29 or i==30 or i==34 or i==35):\n",
    "#         maze.append([0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0])\n",
    "#     elif (i==2 or i==7 or i==12 or i==17 or i==22 or i==27 or i==32) :\n",
    "#         maze.append([1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1])\n",
    "#     else : \n",
    "#         maze.append([1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1])\n",
    "maze = get_map()\n",
    "maze = maze.astype(float)\n",
    "maze.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 87186,
     "status": "ok",
     "timestamp": 1593147077600,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "7vAa9PvDEv0O"
   },
   "outputs": [],
   "source": [
    "visited_mark = 0.8  # Cells visited by the rat will be painted by gray 0.8\n",
    "rat_mark = 0.5      # The current rat cell will be painteg by gray 0.5\n",
    "target_mark = 0.7\n",
    "LEFT1 = 0\n",
    "LEFT2 = 1\n",
    "LEFT3 = 2\n",
    "UP1 = 3\n",
    "UP2 = 4\n",
    "UP3 = 5\n",
    "RIGHT1 = 6\n",
    "RIGHT2 = 7\n",
    "RIGHT3 = 8\n",
    "DOWN1 = 9\n",
    "DOWN2 = 10\n",
    "DOWN3 = 11\n",
    "\n",
    "# Actions dictionary\n",
    "actions_dict = {\n",
    "    LEFT1: 'left1',\n",
    "    LEFT2: 'left2',\n",
    "    LEFT3: 'left3',\n",
    "    UP1:'up1',\n",
    "    UP2:'up2',\n",
    "    UP3:'up3',\n",
    "    RIGHT1: 'right1',\n",
    "    RIGHT2: 'right2',\n",
    "    RIGHT3: 'right3',\n",
    "    DOWN1: 'down1',\n",
    "    DOWN2: 'down2',\n",
    "    DOWN3: 'down3',\n",
    "}\n",
    "state_centroid_dict = {}\n",
    "num_actions = len(actions_dict)\n",
    "MODEL_NAME = \"model\"\n",
    "# Exploration factor\n",
    "AGGREGATE_STATS_EVERY = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 87184,
     "status": "ok",
     "timestamp": 1593147077601,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "4CA8FigBY-0o"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"D:/Study/RL/RLAChips-V11/data_nguyen\")\n",
    "source_data = glob.glob(\"*.xlsx\")\n",
    "os.getcwd()\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 114515,
     "status": "ok",
     "timestamp": 1593147104943,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "EHCZqC2Rcrdb",
    "outputId": "7dabe51e-425b-4052-90ab-6344ec6868fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Lamda    Output         Loss1     Loss2     pc\n",
      "0  1.525  0.081787  3.120494e-05  0.000153  192.5\n",
      "1  1.530  0.148833  3.441380e-05  0.000243  192.5\n",
      "2  1.535  0.274497  4.577745e-05  0.001259  192.5\n",
      "3  1.540  0.481452  3.673484e-05  0.002275  192.5\n",
      "4  1.545  0.644609  9.567780e-06  0.002368  192.5\n",
      "5  1.550  0.651973  4.227260e-06  0.002534  192.5\n",
      "6  1.555  0.501727  1.284361e-06  0.002775  192.5\n",
      "7  1.560  0.292534  3.142490e-07  0.001900  192.5\n",
      "8  1.565  0.136158  1.971773e-06  0.000478  192.5\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.059389  0.000091  0.000750  184.15\n",
      "1  1.530  0.118085  0.000042  0.001807  184.15\n",
      "2  1.535  0.227252  0.000081  0.001311  184.15\n",
      "3  1.540  0.436841  0.000184  0.000703  184.15\n",
      "4  1.545  0.618331  0.000121  0.000174  184.15\n",
      "5  1.550  0.637778  0.000104  0.000162  184.15\n",
      "6  1.555  0.493877  0.000050  0.000634  184.15\n",
      "7  1.560  0.291929  0.000028  0.000859  184.15\n",
      "8  1.565  0.126916  0.000021  0.000950  184.15\n",
      "   Lamda    Output     Loss1         Loss2     pc\n",
      "0  1.525  0.079659  0.000390  1.350025e-04  174.4\n",
      "1  1.530  0.144708  0.000323  1.044313e-04  174.4\n",
      "2  1.535  0.281011  0.001153  3.742872e-05  174.4\n",
      "3  1.540  0.484184  0.001795  2.249174e-05  174.4\n",
      "4  1.545  0.645909  0.002086  6.102188e-06  174.4\n",
      "5  1.550  0.651711  0.002257  4.898336e-06  174.4\n",
      "6  1.555  0.500847  0.002230  2.051749e-06  174.4\n",
      "7  1.560  0.292534  0.001570  1.488224e-07  174.4\n",
      "8  1.565  0.134318  0.000514  1.500513e-06  174.4\n",
      "   Lamda    Output         Loss1     Loss2     pc\n",
      "0  1.525  0.250632  9.562622e-05  0.000469  311.7\n",
      "1  1.530  0.362174  8.374346e-05  0.000592  311.7\n",
      "2  1.535  0.430490  7.179215e-05  0.001974  311.7\n",
      "3  1.540  0.560135  4.273835e-05  0.002647  311.7\n",
      "4  1.545  0.660890  9.809423e-06  0.002428  311.7\n",
      "5  1.550  0.709544  4.600539e-06  0.002758  311.7\n",
      "6  1.555  0.680922  1.743077e-06  0.003767  311.7\n",
      "7  1.560  0.571186  6.135842e-07  0.003710  311.7\n",
      "8  1.565  0.445504  6.451592e-06  0.001564  311.7\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.181996  0.000280  0.002298  128.65\n",
      "1  1.530  0.287352  0.000101  0.004397  128.65\n",
      "2  1.535  0.356397  0.000127  0.002056  128.65\n",
      "3  1.540  0.508234  0.000214  0.000818  128.65\n",
      "4  1.545  0.633948  0.000124  0.000178  128.65\n",
      "5  1.550  0.694096  0.000113  0.000177  128.65\n",
      "6  1.555  0.670268  0.000068  0.000860  128.65\n",
      "7  1.560  0.570004  0.000055  0.001677  128.65\n",
      "8  1.565  0.415265  0.000070  0.003108  128.65\n",
      "   Lamda    Output     Loss1         Loss2     pc\n",
      "0  1.525  0.240851  0.001179  4.081832e-04  118.9\n",
      "1  1.530  0.335959  0.000750  2.424516e-04  118.9\n",
      "2  1.535  0.453395  0.001861  6.038908e-05  118.9\n",
      "3  1.540  0.568331  0.002106  2.640060e-05  118.9\n",
      "4  1.545  0.663568  0.002143  6.269026e-06  118.9\n",
      "5  1.550  0.709574  0.002457  5.333243e-06  118.9\n",
      "6  1.555  0.680877  0.003031  2.789251e-06  118.9\n",
      "7  1.560  0.576988  0.003097  2.935343e-07  118.9\n",
      "8  1.565  0.438961  0.001679  4.903784e-06  118.9\n",
      "   Lamda    Output         Loss1     Loss2     pc\n",
      "0  1.525  0.244112  9.313857e-05  0.000457  118.9\n",
      "1  1.530  0.352136  8.142241e-05  0.000576  118.9\n",
      "2  1.535  0.440706  7.349589e-05  0.002021  118.9\n",
      "3  1.540  0.563314  4.298086e-05  0.002662  118.9\n",
      "4  1.545  0.662222  9.829198e-06  0.002432  118.9\n",
      "5  1.550  0.709259  4.598689e-06  0.002757  118.9\n",
      "6  1.555  0.679727  1.740019e-06  0.003760  118.9\n",
      "7  1.560  0.571185  6.135832e-07  0.003710  118.9\n",
      "8  1.565  0.439485  6.364418e-06  0.001543  118.9\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.174894  0.000269  0.002208  110.55\n",
      "1  1.530  0.266553  0.000094  0.004078  110.55\n",
      "2  1.535  0.375360  0.000134  0.002165  110.55\n",
      "3  1.540  0.515670  0.000218  0.000830  110.55\n",
      "4  1.545  0.636517  0.000125  0.000179  110.55\n",
      "5  1.550  0.694125  0.000113  0.000177  110.55\n",
      "6  1.555  0.670224  0.000068  0.000860  110.55\n",
      "7  1.560  0.575795  0.000055  0.001694  110.55\n",
      "8  1.565  0.409165  0.000069  0.003062  110.55\n",
      "   Lamda    Output     Loss1         Loss2     pc\n",
      "0  1.525  0.231452  0.001133  3.922539e-04  100.8\n",
      "1  1.530  0.311642  0.000696  2.249025e-04  100.8\n",
      "2  1.535  0.477519  0.001960  6.360226e-05  100.8\n",
      "3  1.540  0.576647  0.002137  2.678690e-05  100.8\n",
      "4  1.545  0.666258  0.002151  6.294437e-06  100.8\n",
      "5  1.550  0.709604  0.002457  5.333469e-06  100.8\n",
      "6  1.555  0.680832  0.003031  2.789066e-06  100.8\n",
      "7  1.560  0.582850  0.003129  2.965163e-07  100.8\n",
      "8  1.565  0.432513  0.001654  4.831754e-06  100.8\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.046432  0.000031  0.001245  221.75\n",
      "1  1.530  0.099559  0.000265  0.007284  221.75\n",
      "2  1.535  0.212386  0.000135  0.002607  221.75\n",
      "3  1.540  0.432511  0.000222  0.014744  221.75\n",
      "4  1.545  0.612943  0.000026  0.002346  221.75\n",
      "5  1.550  0.638623  0.000010  0.000384  221.75\n",
      "6  1.555  0.489225  0.000077  0.007370  221.75\n",
      "7  1.560  0.289780  0.000045  0.001374  221.75\n",
      "8  1.565  0.122256  0.000073  0.001780  221.75\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.030780  0.000208  0.000037  202.25\n",
      "1  1.530  0.082056  0.000060  0.000075  202.25\n",
      "2  1.535  0.162602  0.000285  0.000118  202.25\n",
      "3  1.540  0.368599  0.000020  0.000075  202.25\n",
      "4  1.545  0.583370  0.000039  0.000053  202.25\n",
      "5  1.550  0.612752  0.000017  0.000037  202.25\n",
      "6  1.555  0.476591  0.000052  0.000024  202.25\n",
      "7  1.560  0.281909  0.000011  0.000003  202.25\n",
      "8  1.565  0.114558  0.000013  0.000003  202.25\n",
      "   Lamda    Output     Loss1     Loss2     pc\n",
      "0  1.525  0.039823  0.000819  0.000046  193.9\n",
      "1  1.530  0.091445  0.000046  0.000045  193.9\n",
      "2  1.535  0.163102  0.002065  0.000070  193.9\n",
      "3  1.540  0.371602  0.001379  0.000026  193.9\n",
      "4  1.545  0.585550  0.007167  0.000022  193.9\n",
      "5  1.550  0.577967  0.002390  0.000004  193.9\n",
      "6  1.555  0.380157  0.000977  0.000014  193.9\n",
      "7  1.560  0.173014  0.001094  0.000055  193.9\n",
      "8  1.565  0.051030  0.000704  0.000008  193.9\n",
      "   Lamda    Output     Loss1     Loss2   pc\n",
      "0  1.525  0.165574  0.000110  0.004438  176\n",
      "1  1.530  0.239747  0.000638  0.017541  176\n",
      "2  1.535  0.385887  0.000245  0.004736  176\n",
      "3  1.540  0.530670  0.000273  0.018090  176\n",
      "4  1.545  0.649778  0.000028  0.002487  176\n",
      "5  1.550  0.708384  0.000011  0.000425  176\n",
      "6  1.555  0.660508  0.000104  0.009950  176\n",
      "7  1.560  0.577274  0.000090  0.002738  176\n",
      "8  1.565  0.387174  0.000232  0.005637  176\n",
      "   Lamda    Output     Loss1     Loss2     pc\n",
      "0  1.525  0.109758  0.000742  0.000133  156.5\n",
      "1  1.530  0.197598  0.000143  0.000181  156.5\n",
      "2  1.535  0.295433  0.000518  0.000215  156.5\n",
      "3  1.540  0.452253  0.000024  0.000093  156.5\n",
      "4  1.545  0.618428  0.000042  0.000056  156.5\n",
      "5  1.550  0.679687  0.000019  0.000042  156.5\n",
      "6  1.555  0.643450  0.000070  0.000033  156.5\n",
      "7  1.560  0.561593  0.000022  0.000007  156.5\n",
      "8  1.565  0.362795  0.000040  0.000008  156.5\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.136736  0.002812  0.000159  148.15\n",
      "1  1.530  0.224733  0.000114  0.000111  148.15\n",
      "2  1.535  0.350805  0.004441  0.000150  148.15\n",
      "3  1.540  0.510558  0.001895  0.000036  148.15\n",
      "4  1.545  0.630971  0.007723  0.000023  148.15\n",
      "5  1.550  0.695045  0.002874  0.000004  148.15\n",
      "6  1.555  0.663911  0.001705  0.000025  148.15\n",
      "7  1.560  0.571556  0.003613  0.000181  148.15\n",
      "8  1.565  0.394142  0.005438  0.000062  148.15\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.136736  0.000091  0.003665  148.15\n",
      "1  1.530  0.224733  0.000598  0.016442  148.15\n",
      "2  1.535  0.350805  0.000223  0.004306  148.15\n",
      "3  1.540  0.510558  0.000262  0.017404  148.15\n",
      "4  1.545  0.630971  0.000027  0.002415  148.15\n",
      "5  1.550  0.695045  0.000011  0.000417  148.15\n",
      "6  1.555  0.663911  0.000105  0.010001  148.15\n",
      "7  1.560  0.571556  0.000089  0.002711  148.15\n",
      "8  1.565  0.394142  0.000237  0.005738  148.15\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.090642  0.000612  0.000109  128.65\n",
      "1  1.530  0.185224  0.000134  0.000170  128.65\n",
      "2  1.535  0.268574  0.000471  0.000195  128.65\n",
      "3  1.540  0.435113  0.000023  0.000089  128.65\n",
      "4  1.545  0.600528  0.000041  0.000054  128.65\n",
      "5  1.550  0.666888  0.000019  0.000041  128.65\n",
      "6  1.555  0.646765  0.000070  0.000033  128.65\n",
      "7  1.560  0.556030  0.000022  0.000007  128.65\n",
      "8  1.565  0.369324  0.000041  0.000008  128.65\n",
      "   Lamda    Output     Loss1     Loss2     pc\n",
      "0  1.525  0.112921  0.002322  0.000131  120.3\n",
      "1  1.530  0.210660  0.000106  0.000104  120.3\n",
      "2  1.535  0.318913  0.004037  0.000136  120.3\n",
      "3  1.540  0.491208  0.001823  0.000035  120.3\n",
      "4  1.545  0.612708  0.007499  0.000023  120.3\n",
      "5  1.550  0.681956  0.002820  0.000004  120.3\n",
      "6  1.555  0.667331  0.001714  0.000025  120.3\n",
      "7  1.560  0.565894  0.003577  0.000179  120.3\n",
      "8  1.565  0.401235  0.005536  0.000063  120.3\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.078807  0.000088  0.000184  128.65\n",
      "1  1.530  0.145792  0.000058  0.000077  128.65\n",
      "2  1.535  0.275556  0.000108  0.000378  128.65\n",
      "3  1.540  0.485651  0.000082  0.000523  128.65\n",
      "4  1.545  0.649450  0.000017  0.000274  128.65\n",
      "5  1.550  0.657555  0.000004  0.000083  128.65\n",
      "6  1.555  0.509597  0.000004  0.000027  128.65\n",
      "7  1.560  0.299486  0.000002  0.000112  128.65\n",
      "8  1.565  0.138812  0.000003  0.000293  128.65\n",
      "   Lamda    Output     Loss1     Loss2     pc\n",
      "0  1.525  0.060874  0.000444  0.000186  156.5\n",
      "1  1.530  0.118949  0.001315  0.000358  156.5\n",
      "2  1.535  0.249190  0.000754  0.000286  156.5\n",
      "3  1.540  0.458584  0.000800  0.000191  156.5\n",
      "4  1.545  0.635189  0.000214  0.000091  156.5\n",
      "5  1.550  0.654061  0.000142  0.000066  156.5\n",
      "6  1.555  0.500125  0.000621  0.000024  156.5\n",
      "7  1.560  0.290879  0.000916  0.000015  156.5\n",
      "8  1.565  0.131996  0.000953  0.000024  156.5\n",
      "   Lamda    Output     Loss1         Loss2     pc\n",
      "0  1.525  0.070708  0.000300  3.425167e-04  100.8\n",
      "1  1.530  0.131862  0.000144  1.966190e-04  100.8\n",
      "2  1.535  0.289799  0.000793  1.437102e-04  100.8\n",
      "3  1.540  0.491905  0.000777  8.633561e-05  100.8\n",
      "4  1.545  0.651789  0.000612  1.868983e-05  100.8\n",
      "5  1.550  0.657067  0.000400  4.513758e-06  100.8\n",
      "6  1.555  0.509041  0.000265  8.937343e-07  100.8\n",
      "7  1.560  0.300147  0.000401  1.357330e-06  100.8\n",
      "8  1.565  0.138316  0.000387  2.669397e-06  100.8\n",
      "   Lamda    Output     Loss1     Loss2     pc\n",
      "0  1.525  0.228161  0.000931  0.000631  120.3\n",
      "1  1.530  0.329369  0.001126  0.000234  120.3\n",
      "2  1.535  0.453637  0.000111  0.000433  120.3\n",
      "3  1.540  0.569818  0.000083  0.000557  120.3\n",
      "4  1.545  0.668100  0.000008  0.000227  120.3\n",
      "5  1.550  0.715921  0.000038  0.000047  120.3\n",
      "6  1.555  0.690833  0.000031  0.000038  120.3\n",
      "7  1.560  0.585185  0.000163  0.000210  120.3\n",
      "8  1.565  0.432609  0.000272  0.000996  120.3\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.199797  0.001458  0.000609  148.15\n",
      "1  1.530  0.296867  0.003283  0.000894  148.15\n",
      "2  1.535  0.391366  0.001184  0.000449  148.15\n",
      "3  1.540  0.534454  0.000932  0.000223  148.15\n",
      "4  1.545  0.651524  0.000220  0.000093  148.15\n",
      "5  1.550  0.712375  0.000154  0.000072  148.15\n",
      "6  1.555  0.679444  0.000844  0.000033  148.15\n",
      "7  1.560  0.572461  0.001803  0.000030  148.15\n",
      "8  1.565  0.427069  0.003082  0.000077  148.15\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.232075  0.000985  0.001124  128.65\n",
      "1  1.530  0.329094  0.000359  0.000491  128.65\n",
      "2  1.535  0.455145  0.001246  0.000226  128.65\n",
      "3  1.540  0.573287  0.000906  0.000101  128.65\n",
      "4  1.545  0.668551  0.000627  0.000019  128.65\n",
      "5  1.550  0.715649  0.000436  0.000005  128.65\n",
      "6  1.555  0.691557  0.000360  0.000001  128.65\n",
      "7  1.560  0.590700  0.000789  0.000003  128.65\n",
      "8  1.565  0.447518  0.001251  0.000009  128.65\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.232075  0.000259  0.000541  202.25\n",
      "1  1.530  0.329094  0.000131  0.000174  202.25\n",
      "2  1.535  0.455145  0.000178  0.000624  202.25\n",
      "3  1.540  0.573287  0.000097  0.000617  202.25\n",
      "4  1.545  0.668551  0.000018  0.000282  202.25\n",
      "5  1.550  0.715649  0.000004  0.000090  202.25\n",
      "6  1.555  0.691557  0.000005  0.000036  202.25\n",
      "7  1.560  0.590700  0.000004  0.000222  202.25\n",
      "8  1.565  0.447518  0.000010  0.000945  202.25\n",
      "   Lamda    Output     Loss1     Loss2     pc\n",
      "0  1.525  0.179265  0.001308  0.000547  230.1\n",
      "1  1.530  0.268502  0.002969  0.000809  230.1\n",
      "2  1.535  0.411594  0.001245  0.000472  230.1\n",
      "3  1.540  0.541336  0.000944  0.000226  230.1\n",
      "4  1.545  0.653871  0.000221  0.000094  230.1\n",
      "5  1.550  0.711846  0.000154  0.000072  230.1\n",
      "6  1.555  0.678702  0.000843  0.000033  230.1\n",
      "7  1.560  0.573724  0.001807  0.000030  230.1\n",
      "8  1.565  0.425544  0.003071  0.000077  230.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Lamda    Output     Loss1     Loss2     pc\n",
      "0  1.525  0.208227  0.000884  0.001009  174.4\n",
      "1  1.530  0.297650  0.000325  0.000444  174.4\n",
      "2  1.535  0.478670  0.001310  0.000237  174.4\n",
      "3  1.540  0.580670  0.000917  0.000102  174.4\n",
      "4  1.545  0.670959  0.000629  0.000019  174.4\n",
      "5  1.550  0.715118  0.000436  0.000005  174.4\n",
      "6  1.555  0.690802  0.000359  0.000001  174.4\n",
      "7  1.560  0.592003  0.000791  0.000003  174.4\n",
      "8  1.565  0.445920  0.001247  0.000009  174.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'I1_to_J1': -0.060831490630537596,\n",
       " 'I1_to_J2': -0.07039157926195691,\n",
       " 'I1_to_J3': -0.06100618220166166,\n",
       " 'I1_to_K1': -0.024081738085422133,\n",
       " 'I1_to_K2': -0.03364182671684155,\n",
       " 'I1_to_K3': -0.024063378362385385,\n",
       " 'I1_to_O1': -0.02425642965654643,\n",
       " 'I1_to_O2': -0.033623466993804786,\n",
       " 'I1_to_O3': -0.02404501863934866,\n",
       " 'I2_to_J1': -0.06981675080087654,\n",
       " 'I2_to_J2': -0.08777659117674864,\n",
       " 'I2_to_J3': -0.11315846891863693,\n",
       " 'I2_to_K1': -0.024792541608285847,\n",
       " 'I2_to_K2': -0.042752381984157935,\n",
       " 'I2_to_K3': -0.03304863853272445,\n",
       " 'I2_to_O1': -0.03304863853272445,\n",
       " 'I2_to_O2': -0.05100847890859658,\n",
       " 'I2_to_O3': -0.041304735457163115,\n",
       " 'I3_to_J1': -0.05712925782497559,\n",
       " 'I3_to_J2': -0.0594432556682023,\n",
       " 'I3_to_J3': -0.057451647401003184,\n",
       " 'I3_to_K1': -0.02019621511126152,\n",
       " 'I3_to_K2': -0.02235275382402254,\n",
       " 'I3_to_K3': -0.020361145556823387,\n",
       " 'I3_to_O1': -0.020361145556823536,\n",
       " 'I3_to_O2': -0.02267514340005018,\n",
       " 'I3_to_O3': -0.02068353513285113}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = {}\n",
    "pc={}\n",
    "for file in source_data :\n",
    "  data = pd.read_excel(file,header=0)\n",
    "  print(data)\n",
    "  row = data.loc[data['Lamda']==1.5500].values[0][1:]\n",
    "  file_name = file.split('.')[0]\n",
    "  output_loss = row[0]\n",
    "  power_cons = row[3]\n",
    "  #print(output_loss)\n",
    "  df[file_name] = np.log10(output_loss*4/3)\n",
    "  pc[file_name] = power_cons\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I1_to_J1': 192.5,\n",
       " 'I1_to_J2': 184.15,\n",
       " 'I1_to_J3': 174.4,\n",
       " 'I1_to_K1': 311.7,\n",
       " 'I1_to_K2': 128.65,\n",
       " 'I1_to_K3': 118.9,\n",
       " 'I1_to_O1': 118.9,\n",
       " 'I1_to_O2': 110.55,\n",
       " 'I1_to_O3': 100.8,\n",
       " 'I2_to_J1': 221.75,\n",
       " 'I2_to_J2': 202.25,\n",
       " 'I2_to_J3': 193.9,\n",
       " 'I2_to_K1': 176.0,\n",
       " 'I2_to_K2': 156.5,\n",
       " 'I2_to_K3': 148.15,\n",
       " 'I2_to_O1': 148.15,\n",
       " 'I2_to_O2': 128.65,\n",
       " 'I2_to_O3': 120.3,\n",
       " 'I3_to_J1': 128.65,\n",
       " 'I3_to_J2': 156.5,\n",
       " 'I3_to_J3': 100.8,\n",
       " 'I3_to_K1': 120.3,\n",
       " 'I3_to_K2': 148.15,\n",
       " 'I3_to_K3': 128.65,\n",
       " 'I3_to_O1': 202.25,\n",
       " 'I3_to_O2': 230.1,\n",
       " 'I3_to_O3': 174.4}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "pc[\"K1_to_O1\"]=pc[\"O1_to_K1\"]=pc[\"J1_to_I3\"]=pc[\"I3_to_J1\"]\n",
    "pc[\"K1_to_O2\"]=pc[\"O1_to_K2\"]=pc[\"J1_to_I2\"]=pc[\"I3_to_J2\"]\n",
    "pc[\"K1_to_O3\"]=pc[\"O1_to_K3\"]=pc[\"J1_to_I1\"]=pc[\"I3_to_J3\"]\n",
    "pc[\"K1_to_J1\"]=pc[\"O1_to_I3\"]=pc[\"J1_to_O1\"]=pc[\"I3_to_K1\"]\n",
    "pc[\"K1_to_J2\"]=pc[\"O1_to_I2\"]=pc[\"J1_to_O2\"]=pc[\"I3_to_K2\"]\n",
    "pc[\"K1_to_J3\"]=pc[\"O1_to_I1\"]=pc[\"J1_to_O3\"]=pc[\"I3_to_K3\"]\n",
    "pc[\"K1_to_I3\"]=pc[\"O1_to_J1\"]=pc[\"J1_to_K1\"]=pc[\"I3_to_O1\"]\n",
    "pc[\"K1_to_I2\"]=pc[\"O1_to_J2\"]=pc[\"J1_to_K2\"]=pc[\"I3_to_O2\"]\n",
    "pc[\"K1_to_I1\"]=pc[\"O1_to_J3\"]=pc[\"J1_to_K3\"]=pc[\"I3_to_O3\"]\n",
    "###########################################################\n",
    "pc[\"K3_to_O1\"]=pc[\"O3_to_K1\"]=pc[\"J3_to_I3\"]=pc[\"I1_to_J1\"]\n",
    "pc[\"K3_to_O2\"]=pc[\"O3_to_K2\"]=pc[\"J3_to_I2\"]=pc[\"I1_to_J2\"]\n",
    "pc[\"K3_to_O3\"]=pc[\"O3_to_K3\"]=pc[\"J3_to_I1\"]=pc[\"I1_to_J3\"]\n",
    "pc[\"K3_to_J1\"]=pc[\"O3_to_I3\"]=pc[\"J3_to_O1\"]=pc[\"I1_to_K1\"]\n",
    "pc[\"K3_to_J2\"]=pc[\"O3_to_I2\"]=pc[\"J3_to_O2\"]=pc[\"I1_to_K2\"]\n",
    "pc[\"K3_to_J3\"]=pc[\"O3_to_I1\"]=pc[\"J3_to_O3\"]=pc[\"I1_to_K3\"]\n",
    "pc[\"K3_to_I3\"]=pc[\"O3_to_J1\"]=pc[\"J3_to_K1\"]=pc[\"I1_to_O1\"]\n",
    "pc[\"K3_to_I2\"]=pc[\"O3_to_J2\"]=pc[\"J3_to_K2\"]=pc[\"I1_to_O2\"]\n",
    "pc[\"K3_to_I1\"]=pc[\"O3_to_J3\"]=pc[\"J3_to_K3\"]=pc[\"I1_to_O3\"]\n",
    "###########################################################\n",
    "pc[\"K2_to_O1\"]=pc[\"O2_to_K1\"]=pc[\"J2_to_I3\"]=pc[\"I2_to_J1\"]\n",
    "pc[\"K2_to_O2\"]=pc[\"O2_to_K2\"]=pc[\"J2_to_I2\"]=pc[\"I2_to_J2\"]\n",
    "pc[\"K2_to_O3\"]=pc[\"O2_to_K3\"]=pc[\"J2_to_I1\"]=pc[\"I2_to_J3\"]\n",
    "pc[\"K2_to_J1\"]=pc[\"O2_to_I3\"]=pc[\"J2_to_O1\"]=pc[\"I2_to_K1\"]\n",
    "pc[\"K2_to_J2\"]=pc[\"O2_to_I2\"]=pc[\"J2_to_O2\"]=pc[\"I2_to_K2\"]\n",
    "pc[\"K2_to_J3\"]=pc[\"O2_to_I1\"]=pc[\"J2_to_O3\"]=pc[\"I2_to_K3\"]\n",
    "pc[\"K2_to_I3\"]=pc[\"O2_to_J1\"]=pc[\"J2_to_K1\"]=pc[\"I2_to_O1\"]\n",
    "pc[\"K2_to_I2\"]=pc[\"O2_to_J2\"]=pc[\"J2_to_K2\"]=pc[\"I2_to_O2\"]\n",
    "pc[\"K2_to_I1\"]=pc[\"O2_to_J3\"]=pc[\"J2_to_K3\"]=pc[\"I2_to_O3\"]\n",
    "###########################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 114505,
     "status": "ok",
     "timestamp": 1593147104944,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "5iYmR0Anxm0w",
    "outputId": "a0266052-6466-405a-c2b7-c3d5468c0ba4"
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "df[\"K1_to_O1\"]=df[\"O1_to_K1\"]=df[\"J1_to_I3\"]=df[\"I3_to_J1\"]\n",
    "df[\"K1_to_O2\"]=df[\"O1_to_K2\"]=df[\"J1_to_I2\"]=df[\"I3_to_J2\"]\n",
    "df[\"K1_to_O3\"]=df[\"O1_to_K3\"]=df[\"J1_to_I1\"]=df[\"I3_to_J3\"]\n",
    "df[\"K1_to_J1\"]=df[\"O1_to_I3\"]=df[\"J1_to_O1\"]=df[\"I3_to_K1\"]\n",
    "df[\"K1_to_J2\"]=df[\"O1_to_I2\"]=df[\"J1_to_O2\"]=df[\"I3_to_K2\"]\n",
    "df[\"K1_to_J3\"]=df[\"O1_to_I1\"]=df[\"J1_to_O3\"]=df[\"I3_to_K3\"]\n",
    "df[\"K1_to_I3\"]=df[\"O1_to_J1\"]=df[\"J1_to_K1\"]=df[\"I3_to_O1\"]\n",
    "df[\"K1_to_I2\"]=df[\"O1_to_J2\"]=df[\"J1_to_K2\"]=df[\"I3_to_O2\"]\n",
    "df[\"K1_to_I1\"]=df[\"O1_to_J3\"]=df[\"J1_to_K3\"]=df[\"I3_to_O3\"]\n",
    "###########################################################\n",
    "df[\"K3_to_O1\"]=df[\"O3_to_K1\"]=df[\"J3_to_I3\"]=df[\"I1_to_J1\"]\n",
    "df[\"K3_to_O2\"]=df[\"O3_to_K2\"]=df[\"J3_to_I2\"]=df[\"I1_to_J2\"]\n",
    "df[\"K3_to_O3\"]=df[\"O3_to_K3\"]=df[\"J3_to_I1\"]=df[\"I1_to_J3\"]\n",
    "df[\"K3_to_J1\"]=df[\"O3_to_I3\"]=df[\"J3_to_O1\"]=df[\"I1_to_K1\"]\n",
    "df[\"K3_to_J2\"]=df[\"O3_to_I2\"]=df[\"J3_to_O2\"]=df[\"I1_to_K2\"]\n",
    "df[\"K3_to_J3\"]=df[\"O3_to_I1\"]=df[\"J3_to_O3\"]=df[\"I1_to_K3\"]\n",
    "df[\"K3_to_I3\"]=df[\"O3_to_J1\"]=df[\"J3_to_K1\"]=df[\"I1_to_O1\"]\n",
    "df[\"K3_to_I2\"]=df[\"O3_to_J2\"]=df[\"J3_to_K2\"]=df[\"I1_to_O2\"]\n",
    "df[\"K3_to_I1\"]=df[\"O3_to_J3\"]=df[\"J3_to_K3\"]=df[\"I1_to_O3\"]\n",
    "###########################################################\n",
    "df[\"K2_to_O1\"]=df[\"O2_to_K1\"]=df[\"J2_to_I3\"]=df[\"I2_to_J1\"]\n",
    "df[\"K2_to_O2\"]=df[\"O2_to_K2\"]=df[\"J2_to_I2\"]=df[\"I2_to_J2\"]\n",
    "df[\"K2_to_O3\"]=df[\"O2_to_K3\"]=df[\"J2_to_I1\"]=df[\"I2_to_J3\"]\n",
    "df[\"K2_to_J1\"]=df[\"O2_to_I3\"]=df[\"J2_to_O1\"]=df[\"I2_to_K1\"]\n",
    "df[\"K2_to_J2\"]=df[\"O2_to_I2\"]=df[\"J2_to_O2\"]=df[\"I2_to_K2\"]\n",
    "df[\"K2_to_J3\"]=df[\"O2_to_I1\"]=df[\"J2_to_O3\"]=df[\"I2_to_K3\"]\n",
    "df[\"K2_to_I3\"]=df[\"O2_to_J1\"]=df[\"J2_to_K1\"]=df[\"I2_to_O1\"]\n",
    "df[\"K2_to_I2\"]=df[\"O2_to_J2\"]=df[\"J2_to_K2\"]=df[\"I2_to_O2\"]\n",
    "df[\"K2_to_I1\"]=df[\"O2_to_J3\"]=df[\"J2_to_K3\"]=df[\"I2_to_O3\"]\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 114494,
     "status": "ok",
     "timestamp": 1593147104944,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "S46aKVGw-1b8",
    "outputId": "375e1a25-7796-468b-fd9d-a33982d439b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.024063378362385385"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_node_dict = {}\n",
    "action_node_dict[LEFT1]='K1'\n",
    "action_node_dict[LEFT2]='K2'\n",
    "action_node_dict[LEFT3]='K3'\n",
    "action_node_dict[UP1]='J1'\n",
    "action_node_dict[UP2]='J2'\n",
    "action_node_dict[UP3]='J3'\n",
    "action_node_dict[RIGHT1]='O1'\n",
    "action_node_dict[RIGHT2]='O2'\n",
    "action_node_dict[RIGHT3]='O3'\n",
    "action_node_dict[DOWN1]='I1'\n",
    "action_node_dict[DOWN2]='I2'\n",
    "action_node_dict[DOWN3]='I3'\n",
    "df[\"{}_to_{}\".format(action_node_dict[DOWN1],action_node_dict[LEFT3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy(noise_typ,image):\n",
    "    if noise_typ == \"gauss\":\n",
    "      row,col= image.shape\n",
    "      mean = 0\n",
    "      var = 0.01\n",
    "      sigma = var**0.6\n",
    "      gauss = np.random.uniform(low = mean,high = sigma,size = row*col)\n",
    "      gauss = gauss.reshape(row,col)\n",
    "      noisy = image + gauss\n",
    "      return noisy\n",
    "    elif noise_typ == \"s&p\":\n",
    "      row,col = image.shape\n",
    "      s_vs_p = 0.5\n",
    "      amount = 0.004\n",
    "      out = np.copy(image)\n",
    "      # Salt mode\n",
    "      num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "      coords = [np.random.randint(0, i - 1, int(num_salt))\n",
    "              for i in image.shape]\n",
    "      out[coords] = 1\n",
    "\n",
    "      # Pepper mode\n",
    "      num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "      coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
    "              for i in image.shape]\n",
    "      out[coords] = 0\n",
    "      return out\n",
    "    elif noise_typ == \"poisson\":\n",
    "      vals = len(np.unique(image))\n",
    "      vals = 2 ** np.ceil(np.log2(vals))\n",
    "      noisy = np.random.poisson(image * vals) / float(vals)\n",
    "      return noisy\n",
    "    elif noise_typ ==\"speckle\":\n",
    "      row,col = image.shape\n",
    "      gauss = np.random.randn(row,col)\n",
    "      gauss = gauss.reshape(row,col)        \n",
    "      noisy = image + image * gauss\n",
    "      return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 117610,
     "status": "ok",
     "timestamp": 1593147108063,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "DQzW46P1Ewo7"
   },
   "outputs": [],
   "source": [
    "# maze is a 2d Numpy array of floats between 0.0 to 1.0\n",
    "# 1.0 corresponds to a free cell, and 0.0 an occupied cell\n",
    "# rat = (row, col) initial rat position (defaults to (0,0))\n",
    "\n",
    "class Qmaze(object):\n",
    "    def __init__(self, maze, rat=(0,1)):\n",
    "        self._maze = np.array(maze)\n",
    "        nrows, ncols = self._maze.shape\n",
    "        self.target = (nrows-1,ncols-2) # target cell where the \"cheese\" is\n",
    "        self.free_cells = [(r,c) for r in range(nrows) for c in range(ncols) if self._maze[r,c] == 1.0 ]\n",
    "        self.free_target_cells = []\n",
    "        for r in range(nrows):\n",
    "            for c in range(ncols):\n",
    "                if self._maze[r,c] == 1.0 :\n",
    "                    if r == 0 or r == nrows-1 or c == 0 or c == ncols-1:\n",
    "                        self.free_target_cells.append((r,c))\n",
    "#                     if r == nrows-1 :\n",
    "#                         self.free_target_cells.append((r,c))\n",
    "        self.free_cells.remove(self.target)\n",
    "        self.current_distance = None\n",
    "        self.available_cell_target = []\n",
    "        self.centroid = []\n",
    "        self.supervised = 0\n",
    "        self.old_action = 1\n",
    "        self.current_action = None\n",
    "        self.num_non_available_cell = 32\n",
    "        self.state_dim = self.num_non_available_cell*2+4\n",
    "        if self._maze[self.target] == 0.0:\n",
    "            raise Exception(\"Invalid maze: target cell cannot be blocked!\")\n",
    "        if not rat in self.free_cells:\n",
    "            raise Exception(\"Invalid Rat Location: must sit on a free cell\")\n",
    "        self.non_available_cell = random.choices(self.free_cells,k=self.num_non_available_cell)\n",
    "        self.reset(rat,self.target,self.non_available_cell)\n",
    "    def get_list_centroid(self):\n",
    "      dx=[0,2,0,-2,   -2,-1,2,1,    -2,1,2,-1]\n",
    "      dy=[2,0,-2,0,   -1,2,1,-2,    1,2,-1,-2]\n",
    "      for i in range (self._maze.shape[0]):\n",
    "        for j in range (self._maze.shape[1]):\n",
    "          if (self._maze[i][j]==0.95) :\n",
    "            self.centroid.append((i,j))\n",
    "            for temp in range(12):\n",
    "              tx = i + dx[temp]\n",
    "              ty = j + dy[temp]\n",
    "              state_centroid_dict[(tx,ty)] = (i,j)\n",
    "    def available_cell_for_agent(self):\n",
    "        list_available_cell_agent = []\n",
    "        nrows, ncols = self._maze.shape\n",
    "        for row in range(nrows) :\n",
    "            for col in range(ncols) :\n",
    "              if row == 1 or row == 2 or row == 3 or row ==6 or row == 7 or row ==8 or row == 11 or row == 12 or row == 13 :\n",
    "                if col == 0 or col == 14 :\n",
    "                      list_available_cell_agent.append((row,col))\n",
    "              if col== 1 or col == 2 or col == 3 or col ==6 or col == 7 or col ==8 or col == 11 or col == 12 or col == 13 :\n",
    "                if row == 0 or row == 14 :\n",
    "                      list_available_cell_agent.append((row,col))\n",
    "                if row == nrows-1 :\n",
    "                      self.available_cell_target.append((row,col))\n",
    "        return list_available_cell_agent\n",
    "    \n",
    "    def reset(self, rat,target,non_available_cell):\n",
    "        self.rat = rat\n",
    "        self._maze = get_map()\n",
    "        nrows, ncols = self._maze.shape\n",
    "        row, col = rat\n",
    "        self._maze[row, col] = rat_mark\n",
    "        self.state = (row, col, 'valid')\n",
    "        self.min_reward = -256\n",
    "        self.total_reward = 0\n",
    "        self.visited = set()\n",
    "        self.target = target\n",
    "        target_row,target_col = self.target\n",
    "        self.old_distance = -999\n",
    "        self.list_previous_state=[]\n",
    "        self.non_available_cell = non_available_cell\n",
    "        return self.observe().reshape(1,self.state_dim)\n",
    "    def check_state_centroid(self):\n",
    "      nrow, ncol, nmode = rat_row, rat_col, mode = self.state\n",
    "\n",
    "\n",
    "    def update_state(self, action):\n",
    "        nrows, ncols = self._maze.shape\n",
    "        nrow, ncol, nmode = rat_row, rat_col, mode = self.state\n",
    "        if self._maze[rat_row, rat_col] > 0:\n",
    "            self.visited.add((rat_row, rat_col))  # mark visited cell\n",
    "\n",
    "        valid_actions = self.valid_actions()\n",
    "        x_centroid,y_centroid = state_centroid_dict[(nrow, ncol)]\n",
    "        if not valid_actions:\n",
    "            nmode = 'blocked'\n",
    "        elif action in valid_actions:\n",
    "            nmode = 'valid'\n",
    "            dx=[0,2,0,-2,   -2,-1,2,1,    -2,1,2,-1]\n",
    "            dy=[2,0,-2,0,   -1,2,1,-2,    1,2,-1,-2]\n",
    "            #r2,d2,l2,u2,u1,r1,d3,l3,u3,r3,d1,l1\n",
    "            #0 ,1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10 ,11\n",
    "            if action == LEFT1:\n",
    "              if self._maze[nrow][ncol-1]== 1 and self._maze[nrow][ncol+1]== 0.9:\n",
    "                x_centroid +=dx[11]\n",
    "                y_centroid +=(dy[11]-1)\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[11]\n",
    "                y_centroid +=dy[11]\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == LEFT2:\n",
    "              if self._maze[nrow][ncol-1]== 1 and self._maze[nrow][ncol+1]== 0.9:\n",
    "                x_centroid +=dx[2]\n",
    "                y_centroid +=(dy[2]-1)\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[2]\n",
    "                y_centroid +=dy[2]\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == LEFT3:\n",
    "              if self._maze[nrow][ncol-1]== 1 and self._maze[nrow][ncol+1]== 0.9:\n",
    "                x_centroid +=dx[7]\n",
    "                y_centroid +=(dy[7]-1)\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[7]\n",
    "                y_centroid +=dy[7]\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == RIGHT1:\n",
    "              if self._maze[nrow][ncol+1]== 1 and self._maze[nrow][ncol-1]== 0.9:\n",
    "                x_centroid +=dx[5]\n",
    "                y_centroid +=(dy[5]+1)\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[5]\n",
    "                y_centroid +=dy[5]\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == RIGHT2:\n",
    "              if self._maze[nrow][ncol+1]== 1 and self._maze[nrow][ncol-1]== 0.9:\n",
    "                x_centroid +=dx[0]\n",
    "                y_centroid +=(dy[0]+1)\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[0]\n",
    "                y_centroid +=dy[0]\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == RIGHT3:\n",
    "              if self._maze[nrow][ncol+1]== 1 and self._maze[nrow][ncol-1]== 0.9:\n",
    "                x_centroid +=dx[9]\n",
    "                y_centroid +=(dy[9]+1)\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[9]\n",
    "                y_centroid +=dy[9]\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == DOWN1:\n",
    "              if self._maze[nrow+1][ncol]== 1 and self._maze[nrow-1][ncol]== 0.9:\n",
    "                x_centroid +=(dx[10]+1)\n",
    "                y_centroid +=dy[10]\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[10]\n",
    "                y_centroid +=dy[10]\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == DOWN2:\n",
    "              if self._maze[nrow+1][ncol]== 1 and self._maze[nrow-1][ncol]== 0.9:\n",
    "                x_centroid +=(dx[1]+1)\n",
    "                y_centroid +=dy[1]\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[1]\n",
    "                y_centroid +=dy[1]\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == DOWN3:\n",
    "              if self._maze[nrow+1][ncol]== 1 and self._maze[nrow-1][ncol]== 0.9:\n",
    "                x_centroid +=(dx[6]+1)\n",
    "                y_centroid +=dy[6]\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[6]\n",
    "                y_centroid +=dy[6]\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == UP1:\n",
    "              if self._maze[nrow-1][ncol]== 1 and self._maze[nrow+1][ncol]== 0.9:\n",
    "                x_centroid +=(dx[4]-1)\n",
    "                y_centroid +=dy[4]\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[4]\n",
    "                y_centroid +=dy[4]\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == UP2:\n",
    "              if self._maze[nrow-1][ncol]== 1 and self._maze[nrow+1][ncol]== 0.9:\n",
    "                x_centroid +=(dx[3]-1)\n",
    "                y_centroid +=dy[3]\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[3]\n",
    "                y_centroid +=dy[3]\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == UP3:\n",
    "              if self._maze[nrow-1][ncol]== 1 and self._maze[nrow+1][ncol]== 0.9:\n",
    "                x_centroid +=(dx[8]-1)\n",
    "                y_centroid +=dy[8]\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[8]\n",
    "                y_centroid +=dy[8]\n",
    "                if self._maze[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "        else:                  # invalid action, no change in rat position\n",
    "            #nmode = 'invalid'\n",
    "            pass\n",
    "\n",
    "    def get_reward(self):\n",
    "        rat_row, rat_col, mode = self.state\n",
    "        target_row,target_col = self.target\n",
    "        nrows, ncols = self._maze.shape\n",
    "        reward = None\n",
    "        status = None\n",
    "        if mode == 'reward_unchanged'and not (rat_row, rat_col) in self.visited:\n",
    "          #mode = \"valid\"\n",
    "          return 0\n",
    "#         if self.current_action == self.old_action :\n",
    "#           return -1.2\n",
    "        if mode == 'blocked':\n",
    "            reward  =self.min_reward - 0.5\n",
    "        if (rat_row, rat_col) in self.visited:\n",
    "            return -1.5\n",
    "        if mode == 'invalid':\n",
    "            reward  = -2\n",
    "        # if mode == 'valid':\n",
    "        #     reward  = -0.04\n",
    "        if mode == 'valid':\n",
    "            # self.current_distance = self.dist(rat_row,rat_col,target_row,target_col)\n",
    "            # if self.current_distance <= self.old_distance :\n",
    "            #       reward = -self.current_distance*0.004\n",
    "                  \n",
    "            # else : reward = -self.current_distance*0.005\n",
    "            # self.old_distance = self.current_distance\n",
    "            try : \n",
    "              reward = df[\"{}_to_{}\".format(action_node_dict[self.old_action],action_node_dict[self.current_action])]\n",
    "            except :\n",
    "              reward = -1\n",
    "        if rat_row == target_row and rat_col == target_col:\n",
    "            status = 'win'\n",
    "            return 2\n",
    "        # if mode == 'valid' and status !='win':\n",
    "        #       self.current_distance = self.dist(rat_row,rat_col,target_row,target_col)\n",
    "        #       if (rat_row, rat_col) in self.visited :\n",
    "        #           reward = -0.25\n",
    "        #       elif self.current_distance >= self.old_distance :\n",
    "        #       #reward = -current_distance*0.001\n",
    "        #           reward = -0.1             \n",
    "        #       else : reward = -0.04\n",
    "        #       self.old_distance = self.current_distance\n",
    "        return reward\n",
    "    def dist(self,x1,y1,x2,y2):\n",
    "        return ((x2-x1)**2 + (y2-y1)**2)**0.5\n",
    "    def act(self, action):\n",
    "        self.update_state(action)\n",
    "        reward = self.get_reward()\n",
    "        self.total_reward += reward\n",
    "        status = self.game_status()\n",
    "        envstate = self.observe()\n",
    "        return envstate, reward, status\n",
    "    def act_to_predict(self, action):\n",
    "        self.update_state_to_predict(action)\n",
    "        status = self.game_status_to_predict()\n",
    "        envstate = self.observe()\n",
    "        return envstate, status\n",
    "\n",
    "    def observe(self):\n",
    "        canvas = self.draw_env(self.non_available_cell)\n",
    "        envstate = np.reshape(canvas,newshape=(1,self.state_dim))\n",
    "        return envstate\n",
    "\n",
    "    def draw_env(self, non_available_cell):\n",
    "        self._maze = get_map()\n",
    "        row, col = self.rat\n",
    "        self._maze[row, col] = rat_mark\n",
    "        canvas = np.copy(self._maze)\n",
    "        nrows, ncols = self._maze.shape\n",
    "        # clear all visual marks\n",
    "        for r in range(nrows):\n",
    "            for c in range(ncols):\n",
    "                if canvas[r,c] > 0.0:\n",
    "                    canvas[r,c] = 1.0\n",
    "                if (r,c) in  non_available_cell:\n",
    "                    canvas[r,c] = 0.0\n",
    "                    self._maze[r,c]= 0.0\n",
    "        # draw the rat\n",
    "        for row,col in self.visited:\n",
    "            canvas[row,col] = 0.6\n",
    "        row, col, valid = self.state\n",
    "        row_target,col_target =  self.target\n",
    "        canvas[row, col] = rat_mark\n",
    "        canvas[row_target,col_target] = target_mark\n",
    "        #canvas = noisy(\"gauss\",canvas)\n",
    "        input_state = [row,col,row_target,col_target]\n",
    "        for item in non_available_cell:\n",
    "            input_state.append(item[0])\n",
    "            input_state.append(item[1])\n",
    "        input_state = np.asarray(input_state).reshape(-1, 1)\n",
    "        std_scale = preprocessing.StandardScaler().fit(input_state)\n",
    "        input_state = std_scale.transform(input_state)\n",
    "        return input_state\n",
    "\n",
    "    def game_status(self):\n",
    "        if self.total_reward < self.min_reward:\n",
    "            return 'lose'\n",
    "        rat_row, rat_col, mode = self.state\n",
    "        nrows, ncols = self._maze.shape\n",
    "        target_row,target_col = self.target\n",
    "        if rat_row == target_row and rat_col == target_col:\n",
    "            return 'win'\n",
    "\n",
    "        return 'not_over'\n",
    "    def set_supervised(self,supervised):\n",
    "        self.supervised = supervised \n",
    "    def game_status_to_predict(self):\n",
    "        rat_row, rat_col, mode = self.state\n",
    "        target_row,target_col = self.target\n",
    "        if rat_row == target_row and rat_col == target_col:\n",
    "            return 'win'\n",
    "\n",
    "        return 'not_over'\n",
    "\n",
    "    def valid_actions(self, cell=None):\n",
    "        if cell is None:\n",
    "            row, col, mode = self.state\n",
    "        else:\n",
    "            row, col = cell\n",
    "        actions = [LEFT1, LEFT2, LEFT3, RIGHT1, RIGHT2, RIGHT3, UP1, UP2, UP3, DOWN1, DOWN2, DOWN3]\n",
    "        nrows, ncols = self._maze.shape\n",
    "        if row == 0:\n",
    "            actions.remove(UP1)\n",
    "            actions.remove(UP2)\n",
    "            actions.remove(UP3)\n",
    "        elif row == nrows-1:\n",
    "            actions.remove(DOWN1)\n",
    "            actions.remove(DOWN2)\n",
    "            actions.remove(DOWN3)\n",
    "        if col == 0:\n",
    "            actions.remove(LEFT1)\n",
    "            actions.remove(LEFT2)\n",
    "            actions.remove(LEFT3)\n",
    "        elif col == ncols-1:\n",
    "            actions.remove(RIGHT1)\n",
    "            actions.remove(RIGHT2)\n",
    "            actions.remove(RIGHT3)\n",
    "        # if row>0 and self.maze[row-1,col] == 0.0:\n",
    "        #     actions.remove(UP1)\n",
    "        #     actions.remove(UP2)\n",
    "        #     actions.remove(UP3)\n",
    "        #     actions.remove(UP4)\n",
    "        # if row<nrows-1 and self.maze[row+1,col] == 0.0:\n",
    "        #     actions.remove(DOWN1)\n",
    "        #     actions.remove(DOWN2)\n",
    "        #     actions.remove(DOWN3)\n",
    "        #     actions.remove(DOWN4)\n",
    "        # if col>0 and self.maze[row,col-1] == 0.0:\n",
    "        #     actions.remove(LEFT1)\n",
    "        #     actions.remove(LEFT2)\n",
    "        #     actions.remove(LEFT3)\n",
    "        #     actions.remove(LEFT4)\n",
    "        # if col<ncols-1 and self.maze[row,col+1] == 0.0:\n",
    "        #     actions.remove(RIGHT1)\n",
    "        #     actions.remove(RIGHT2)\n",
    "        #     actions.remove(RIGHT3)\n",
    "        #     actions.remove(RIGHT4)\n",
    "        dx=[0,2,0,-2,   -2,-1,2,1,    -2,1,2,-1]\n",
    "        dy=[2,0,-2,0,   -1,2,1,-2,    1,2,-1,-2]\n",
    "        #r2,d2,l2,u2,u1,r1,d3,l3,u3,r3,d1,l1\n",
    "        #0 ,1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10 ,11\n",
    "        tx_target,ty_target = self.target\n",
    "        if self.supervised == 1:\n",
    "            best_choice = None\n",
    "            best_distance = 999999\n",
    "            for action in actions :\n",
    "                x_centroid,y_centroid = state_centroid_dict[(row, col)]\n",
    "                if action == LEFT1:\n",
    "                    if self._maze[row][col-1]== 1 and self._maze[row][col+1]== 0.9:\n",
    "                        x_centroid +=dx[11]\n",
    "                        y_centroid +=(dy[11]-1)\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[11]\n",
    "                        y_centroid +=dy[11]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._maze[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == LEFT2:\n",
    "                    if self._maze[row][col-1]== 1 and self._maze[row][col+1]== 0.9:\n",
    "                        x_centroid +=dx[2]\n",
    "                        y_centroid +=(dy[2]-1)\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target) \n",
    "                    else :\n",
    "                        x_centroid +=dx[2]\n",
    "                        y_centroid +=dy[2]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._maze[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == LEFT3:\n",
    "                    if self._maze[row][col-1]== 1 and self._maze[row][col+1]== 0.9:\n",
    "                        x_centroid +=dx[7]\n",
    "                        y_centroid +=(dy[7]-1)\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[7]\n",
    "                        y_centroid +=dy[7]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._maze[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == RIGHT1:\n",
    "                    if self._maze[row][col+1]== 1 and self._maze[row][col-1]== 0.9:\n",
    "                        x_centroid +=dx[5]\n",
    "                        y_centroid +=(dy[5]+1)\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[5]\n",
    "                        y_centroid +=dy[5]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._maze[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == RIGHT2:\n",
    "                    if self._maze[row][col+1]== 1 and self._maze[row][col-1]== 0.9:\n",
    "                        x_centroid +=dx[0]\n",
    "                        y_centroid +=(dy[0]+1)\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[0]\n",
    "                        y_centroid +=dy[0]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._maze[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == RIGHT3:\n",
    "                    if self._maze[row][col+1]== 1 and self._maze[row][col-1]== 0.9:\n",
    "                        x_centroid +=dx[9]\n",
    "                        y_centroid +=(dy[9]+1)\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[9]\n",
    "                        y_centroid +=dy[9]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._maze[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == DOWN1:\n",
    "                    if self._maze[row+1][col]== 1 and self._maze[row-1][col]== 0.9:\n",
    "                        x_centroid +=(dx[10]+1)\n",
    "                        y_centroid +=dy[10]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[10]\n",
    "                        y_centroid +=dy[10]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._maze[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == DOWN2:\n",
    "                    if self._maze[row+1][col]== 1 and self._maze[row-1][col]== 0.9:\n",
    "                        x_centroid +=(dx[1]+1)\n",
    "                        y_centroid +=dy[1]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[1]\n",
    "                        y_centroid +=dy[1]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._maze[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == DOWN3:\n",
    "                    if self._maze[row+1][col]== 1 and self._maze[row-1][col]== 0.9:\n",
    "                        x_centroid +=(dx[6]+1)\n",
    "                        y_centroid +=dy[6]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[6]\n",
    "                        y_centroid +=dy[6]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._maze[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == UP1:\n",
    "                    if self._maze[row-1][col]== 1 and self._maze[row+1][col]== 0.9:\n",
    "                        x_centroid +=(dx[4]-1)\n",
    "                        y_centroid +=dy[4]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[4]\n",
    "                        y_centroid +=dy[4]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._maze[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == UP2:\n",
    "                    if self._maze[row-1][col]== 1 and self._maze[row+1][col]== 0.9:\n",
    "                        x_centroid +=(dx[3]-1)\n",
    "                        y_centroid +=dy[3]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[3]\n",
    "                        y_centroid +=dy[3]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._maze[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == UP3:\n",
    "                    if self._maze[row-1][col]== 1 and self._maze[row+1][col]== 0.9:\n",
    "                        x_centroid +=(dx[8]-1)\n",
    "                        y_centroid +=dy[8]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[8]\n",
    "                        y_centroid +=dy[8]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._maze[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                if (cur_distance<best_distance):\n",
    "                    best_distance = cur_distance\n",
    "                    best_choice = action\n",
    "                #print(\"Best distance : \",best_distance, \" Best choice : \",best_choice)\n",
    "            actions.clear()\n",
    "            actions.append(best_choice)\n",
    "        return actions\n",
    "    def check_valid_with_previous_state(self,cell):\n",
    "        row_cell, col_cell = cell\n",
    "        for temp in self.visited:\n",
    "            row, col = temp\n",
    "            if row_cell == row and col_cell == col :\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 117608,
     "status": "ok",
     "timestamp": 1593147108064,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "HYi1PiaNEwwH"
   },
   "outputs": [],
   "source": [
    "def show(qmaze):\n",
    "    plt.grid('on')\n",
    "    nrows, ncols = qmaze._maze.shape\n",
    "    row_target,col_target = qmaze.target\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks(np.arange(0.5, nrows+20, 1))\n",
    "    ax.set_yticks(np.arange(0.5, ncols+20, 1))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    canvas = np.copy(qmaze._maze)\n",
    "    for row,col in qmaze.visited:\n",
    "        canvas[row,col] = 0.7\n",
    "    rat_row, rat_col, _ = qmaze.state\n",
    "    canvas[rat_row, rat_col] = 0.3   # rat cell\n",
    "    canvas[row_target,col_target] = 0.2 # cheese cell\n",
    "    img = plt.imshow(canvas, interpolation='none', cmap='Reds_r')\n",
    "    plt.show()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 117596,
     "status": "ok",
     "timestamp": 1593147108066,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "aHUTI80rEw3-",
    "outputId": "b77175da-9b8f-46d7-a72d-2c9ce1f9a708",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27a217d0310>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_width, img_height = maze.shape\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_height, img_width)\n",
    "else:\n",
    "    input_shape = (img_height,img_width, 1)\n",
    "qmaze = Qmaze(maze)\n",
    "qmaze.get_list_centroid()\n",
    "# canvas, reward, game_over = qmaze.act(DOWN)\n",
    "# print(\"reward=\", reward)\n",
    "show(qmaze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 118292,
     "status": "ok",
     "timestamp": 1593147108772,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "jK31MzS0Ew_s",
    "outputId": "35750b8b-36fd-48cd-eb4d-185ad6e1b885"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27a217e7340>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qmaze.act(LEFT1) \n",
    "#qmaze.act(RIGHT2)\n",
    "qmaze.act(DOWN3)  # move down\n",
    "qmaze.act(DOWN3)  # move right\n",
    "qmaze.act(RIGHT2)  # move right\n",
    "qmaze.act(DOWN3)  # move right\n",
    "qmaze.act(UP1)  # move up\n",
    "qmaze.act(DOWN3)  # move up\n",
    "show(qmaze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1539,
     "status": "ok",
     "timestamp": 1593149619964,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "uYXPeyapI47z"
   },
   "outputs": [],
   "source": [
    "def dist(x1,y1,x2,y2):\n",
    "        return ((x2-x1)**2 + (y2-y1)**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 968,
     "status": "ok",
     "timestamp": 1593149621588,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "OnzTJZUc4onl"
   },
   "outputs": [],
   "source": [
    "class ModifiedTensorBoard(TensorBoard):\n",
    "\n",
    "    # Overriding init to set initial step and writer (we want one log file for all .fit() calls)\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.step = 1\n",
    "        #self.writer = tf.summary.FileWriter(self.log_dir)\n",
    "        self.writer = tf.summary.create_file_writer(self.log_dir)\n",
    "    # Overriding this method to stop creating default log writer\n",
    "    def set_model(self, model):\n",
    "        pass\n",
    "\n",
    "    # Overrided, saves logs with our step number\n",
    "    # (otherwise every .fit() will start writing from 0th step)\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.update_stats(**logs)\n",
    "\n",
    "    # Overrided\n",
    "    # We train for one batch only, no need to save anything at epoch end\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        pass\n",
    "\n",
    "    # Overrided, so won't close writer\n",
    "    def on_train_end(self, _):\n",
    "        pass\n",
    "\n",
    "    # Custom method for saving own metrics\n",
    "    # Creates writer, writes custom metrics and closes writer\n",
    "    def update_stats(self, **stats):\n",
    "        #self._write_logs(stats, self.step)\n",
    "        with self.writer.as_default():\n",
    "            tf.summary.scalar(stats, step=self.step)\n",
    "            self.writer.flush()\n",
    "\n",
    "    def _write_logs(self, logs, index):\n",
    "        self.writer.reopen()\n",
    "        for name, value in logs.items():\n",
    "            if name in ['batch', 'size']:\n",
    "                continue\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            if isinstance(value, np.ndarray):\n",
    "                summary_value.simple_value = value.item()\n",
    "            else:\n",
    "                summary_value.simple_value = value\n",
    "            summary_value.tag = name\n",
    "            #self.writer.add_summary(summary, index)\n",
    "            with self.writer.as_default():\n",
    "                tf.summary.scalar(name, summary, index)\n",
    "                self.writer.flush()\n",
    "        self.writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 941,
     "status": "ok",
     "timestamp": 1593149622607,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "VjXoRo7gE0Q0",
    "outputId": "2ddac579-f89a-41c4-8ab4-a096ab7b3fc4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode :  1  Probability :  [0.07509761 0.07214145 0.0914325  0.09936148 0.07184932 0.07185426\n",
      " 0.1458907  0.08637878 0.02565553 0.07981787 0.11225861 0.06826195] \n",
      " Action :  8  Reward :  -1.5  Loss :  -0.6100618220166166  Win count :  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128 samples\n",
      "Epoch 1/16\n",
      "128/128 [==============================] - 1s 6ms/sample - loss: 1.1130\n",
      "Epoch 2/16\n",
      "128/128 [==============================] - 0s 475us/sample - loss: 1.1120\n",
      "Epoch 3/16\n",
      "128/128 [==============================] - 0s 429us/sample - loss: 1.1112\n",
      "Epoch 4/16\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 1.1102\n",
      "Epoch 5/16\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 1.1095\n",
      "Epoch 6/16\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 1.1086\n",
      "Epoch 7/16\n",
      "128/128 [==============================] - 0s 421us/sample - loss: 1.1077\n",
      "Epoch 8/16\n",
      "128/128 [==============================] - 0s 413us/sample - loss: 1.1071\n",
      "Epoch 9/16\n",
      "128/128 [==============================] - 0s 452us/sample - loss: 1.1067\n",
      "Epoch 10/16\n",
      "128/128 [==============================] - 0s 440us/sample - loss: 1.1062\n",
      "Epoch 11/16\n",
      "128/128 [==============================] - 0s 429us/sample - loss: 1.1057\n",
      "Epoch 12/16\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 1.1052\n",
      "Epoch 13/16\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 1.1048\n",
      "Epoch 14/16\n",
      "128/128 [==============================] - 0s 389us/sample - loss: 1.1045\n",
      "Epoch 15/16\n",
      "128/128 [==============================] - 0s 335us/sample - loss: 1.1042\n",
      "Epoch 16/16\n",
      "128/128 [==============================] - 0s 374us/sample - loss: 1.1039\n",
      "Train on 128 samples\n",
      "Epoch 1/16\n",
      "128/128 [==============================] - 1s 5ms/sample - loss: 1.5272\n",
      "Epoch 2/16\n",
      "128/128 [==============================] - 0s 351us/sample - loss: 1.4640\n",
      "Epoch 3/16\n",
      "128/128 [==============================] - 0s 335us/sample - loss: 1.4071\n",
      "Epoch 4/16\n",
      "128/128 [==============================] - 0s 335us/sample - loss: 1.3545\n",
      "Epoch 5/16\n",
      "128/128 [==============================] - 0s 343us/sample - loss: 1.3040\n",
      "Epoch 6/16\n",
      "128/128 [==============================] - 0s 335us/sample - loss: 1.2539\n",
      "Epoch 7/16\n",
      "128/128 [==============================] - 0s 319us/sample - loss: 1.2102\n",
      "Epoch 8/16\n",
      "128/128 [==============================] - 0s 351us/sample - loss: 1.1698\n",
      "Epoch 9/16\n",
      "128/128 [==============================] - 0s 343us/sample - loss: 1.1327\n",
      "Epoch 10/16\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 1.0957\n",
      "Epoch 11/16\n",
      "128/128 [==============================] - 0s 319us/sample - loss: 1.0629\n",
      "Epoch 12/16\n",
      "128/128 [==============================] - 0s 319us/sample - loss: 1.0321\n",
      "Epoch 13/16\n",
      "128/128 [==============================] - 0s 320us/sample - loss: 1.0036\n",
      "Epoch 14/16\n",
      "128/128 [==============================] - 0s 319us/sample - loss: 0.9766\n",
      "Epoch 15/16\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 0.9519\n",
      "Epoch 16/16\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 0.9304\n",
      "updating stats...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "scalar() missing 1 required positional argument: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-6e521ff195e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[1;31m#tensorboard.update_stats(tranmission_loss=loss_sum)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             tensorboard.update_stats(reward_avg=average_reward, reward_min=min_reward,\n\u001b[0m\u001b[0;32m    112\u001b[0m                                            \u001b[0mreward_max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_reward\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mavarage_tranmission_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maverage_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                                            \u001b[0mavarage_power_consumption\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maverage_pwc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-140-6f89e2c24bbf>\u001b[0m in \u001b[0;36mupdate_stats\u001b[1;34m(self, **stats)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m#self._write_logs(stats, self.step)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: scalar() missing 1 required positional argument: 'data'"
     ]
    }
   ],
   "source": [
    "TRAIN_ITERATIONS = 50\n",
    "MAX_EPISODE_LENGTH = 128\n",
    "TRAJECtoRY_BUFFER_SIZE = 32\n",
    "BATCH_SIZE = 16\n",
    "RENDER_EVERY = 100\n",
    "AGGREGATE_STATS_EVERY = 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.chdir(\"D:/Study/RL/RLAChips-V11\")\n",
    "    img_height, img_width = maze.shape\n",
    "    env = Qmaze(maze)\n",
    "    num_states = maze.size\n",
    "    state_dim = env.state_dim\n",
    "    input_dim, output_dim = state_dim, num_actions\n",
    "    lr, gamma, loss_clipping, c1, lamda = 1e-6, 0.99 , 0.2, 0.001, 0.95\n",
    "    agent = Agent(input_dim, output_dim, lr, gamma, loss_clipping, c1,lamda)\n",
    "    tensorboard = ModifiedTensorBoard(log_dir=\"logs/{}-{}\".format(MODEL_NAME, int(time.time())))\n",
    "    EPISODES = 200000\n",
    "    MODEL_NAME = \"model\"\n",
    "    AGGREGATE_STATS_EVERY = 1\n",
    "    ep_rewards=[]\n",
    "    ep_loss = []\n",
    "    ep_pw = []\n",
    "    win_count = 0\n",
    "    num_non_cell = 32\n",
    "    supervision_factor = 0.5\n",
    "    for e in range(1,EPISODES+1):\n",
    "        rat_cell = random.choice(env.free_cells)\n",
    "        non_available_cell = random.choices(env.free_cells,k=num_non_cell)\n",
    "        target_cell = random.choice(env.free_target_cells)\n",
    "        #target_cell = (34,33)\n",
    "        state = env.reset(rat_cell,target_cell,non_available_cell)\n",
    "#         for i in non_available_cell:\n",
    "#             print(i,env._maze[i[0]][i[1]+1])\n",
    "#             time.sleep(2)\n",
    "        r_sum = 0\n",
    "        loss_sum =0 \n",
    "        reward_sum = 0\n",
    "        power_sum = 0\n",
    "        done = False\n",
    "        if e % 1000==0:\n",
    "            clear_output(wait=True)\n",
    "        for cnt_step in range(MAX_EPISODE_LENGTH):\n",
    "            show(env)\n",
    "            #time.sleep(0.5)\n",
    "            clear_output(wait=True)\n",
    "            #get action from agent given state\n",
    "            #print(state)\n",
    "            state = np.reshape(state,(-1,state_dim))\n",
    "            action,pi_vec =  agent.act(state)\n",
    "            ran_supervised = np.random.uniform(0,1)\n",
    "            if ran_supervised < supervision_factor:\n",
    "                env.supervised = 1\n",
    "                action = env.valid_actions()[0]\n",
    "                env.supervised = 0\n",
    "            #get s_,r,done\n",
    "            env.current_action = action\n",
    "            next_state, reward, done= env.act(action)\n",
    "            next_state = np.reshape(next_state,(-1,state_dim))\n",
    "#             if cnt_step%10==0:\n",
    "#                 env.non_available_cell = random.choices(env.free_cells,k=num_non_cell)\n",
    "            reward_sum += reward\n",
    "            if done == 'not_over':\n",
    "                done = False\n",
    "            else :\n",
    "                done = True\n",
    "            mask = not done\n",
    "            agent.remember(state, action,mask,pi_vec, reward)\n",
    "            state = next_state\n",
    "            if done == True :\n",
    "                rat_cell = random.choice(env.free_cells)\n",
    "                non_available_cell = random.choices(env.free_cells,k=num_non_cell)\n",
    "                target_cell = random.choice(env.free_target_cells)\n",
    "                #target_cell = (34,33)\n",
    "                state = env.reset(rat_cell,target_cell,non_available_cell)\n",
    "                loss_sum +=10*np.log10(3/4)\n",
    "            if reward==2 :\n",
    "                loss = 0\n",
    "                win_count+=1\n",
    "            elif reward==0 :\n",
    "                loss = 0\n",
    "            elif reward == -1 :\n",
    "                loss = 0\n",
    "            elif reward == -1.5 :\n",
    "                try :\n",
    "                    loss = df[\"{}_to_{}\".format(action_node_dict[env.old_action],action_node_dict[env.current_action])]\n",
    "                except :\n",
    "                    loss = 0\n",
    "            else :\n",
    "                loss = reward\n",
    "            loss_sum+=loss*10\n",
    "            try :\n",
    "                power_sum += pc[\"{}_to_{}\".format(action_node_dict[env.old_action],action_node_dict[env.current_action])]\n",
    "            except :\n",
    "                power_sum +=0\n",
    "            env.old_action = action\n",
    "            print(\"Episode : \",e, \" Probability : \",pi_vec,\"\\n Action : \",action,\" Reward : \",reward,\" Loss : \",loss*10,\" Win count : \",win_count)\n",
    "        agent.train_models()\n",
    "        ep_rewards.append(reward_sum)\n",
    "        ep_loss.append(loss_sum)\n",
    "        ep_pw.append(power_sum)\n",
    "        if  e%AGGREGATE_STATS_EVERY==0 or e == 1 :\n",
    "            print(\"updating stats...\")\n",
    "            average_reward = sum(ep_rewards[-AGGREGATE_STATS_EVERY:]) / len(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "            min_reward = min(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "            max_reward = max(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "            average_loss = sum(ep_loss[-AGGREGATE_STATS_EVERY:]) / len(ep_loss[-AGGREGATE_STATS_EVERY:])\n",
    "            average_pwc = sum(ep_pw[-AGGREGATE_STATS_EVERY:]) / len(ep_pw[-AGGREGATE_STATS_EVERY:])\n",
    "            #tensorboard.update_stats(tranmission_loss=loss_sum)\n",
    "            tensorboard.step = e\n",
    "            tensorboard.update_stats(reward_avg=average_reward, reward_min=min_reward,\n",
    "                                           reward_max=max_reward,avarage_tranmission_loss = average_loss,\n",
    "                                           avarage_power_consumption = average_pwc,\n",
    "                                           epsilon=1)\n",
    "            agent.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ep_rewards = np.asarray(ep_rewards)\n",
    "result_ep_loss = np.asarray(ep_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 121119,
     "status": "aborted",
     "timestamp": 1593147111671,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "ybibrvVfcQiv"
   },
   "outputs": [],
   "source": [
    "rsl = pd.DataFrame(result_ep_loss)\n",
    "rsl.to_excel('rsl.xlsx', index=False, header=False)\n",
    "rsr = pd.DataFrame(result_ep_rewards)\n",
    "rsr.to_excel('rsr.xlsx', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyOslRe9iSuuIZbBBqNQE42x",
   "collapsed_sections": [],
   "name": "Bản sao của RLAChip.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
