{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 87198,
     "status": "ok",
     "timestamp": 1593147077598,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "CwfA47wzHi1X",
    "outputId": "492c3f3f-03dd-4a77-ac38-a6ef388eeb0e",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.impute import SimpleImputer\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from tensorflow import nn ## de goi cac active function\n",
    "from sklearn import tree\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Input,Activation, Dropout, Flatten, Dense\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from collections import namedtuple\n",
    "import matplotlib\n",
    "from keras.callbacks import TensorBoard\n",
    "import tensorboardX\n",
    "from keras.models import load_model\n",
    "from IPython.display import clear_output\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import np_utils ## dung de categorical cac label\n",
    "from sklearn.model_selection import train_test_split  ## dung de tach bo test ra\n",
    "from sklearn.datasets import load_iris\n",
    "import time\n",
    "import datetime\n",
    "from math import pow\n",
    "import random\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from collections import deque\n",
    "import csv\n",
    "from keras.layers import PReLU\n",
    "import math\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from keras_radam import RAdam\n",
    "from sklearn import preprocessing\n",
    "from IPython.display import clear_output\n",
    "from keras.utils import  to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import math\n",
    "from keras.callbacks import History \n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.models import model_from_json\n",
    "from tensorflow.compat.v1.keras.optimizers import Adam\n",
    "import glob\n",
    "from keras.layers import LeakyReLU\n",
    "from mpi_adam import MpiAdam\n",
    "import tf_util as U\n",
    "from agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 35)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcn=[]\n",
    "def get_map():\n",
    "    pcn=[]\n",
    "#     for i in range(30):\n",
    "#         if (i==0 or i==5 or i==6 or i==11 or i==12 or i==17 or i==18 or i == 23 or i== 24 or i==29 or i == 30):\n",
    "#               pcn.append([0,1,1,1,1,0,0,1,1,1,1,0,0,1,1,1,1,0,0,1,1,1,1,0,0,1,1,1,1,0])\n",
    "#         elif (i==2 or i==8 or i==14 or i == 20 or i==26 ) :\n",
    "#               pcn.append([1,0.9,0.95,0.9,0.9,1,1,0.9,0.95,0.9,0.9,1,1,0.9,0.95,0.9,0.9,1,1,0.9,0.95,0.9,0.9,1,1,0.9,0.95,0.9,0.9,1])\n",
    "#         else : \n",
    "#               pcn.append([1,0.9,0.9,0.9,0.9,1,1,0.9,0.9,0.9,0.9,1,1,0.9,0.9,0.9,0.9,1,1,0.9,0.9,0.9,0.9,1,1,0.9,0.9,0.9,0.9,1])\n",
    "#     pcn = np.asarray(pcn)\n",
    "# 36x36 official\n",
    "    for i in range(35):\n",
    "        if (i==0 or i==4 or i==5 or i==9 or i==10 or i==14 or i==15 or i==19 or i==20 or i==24 or i==25 or i==29 or i==30 or i==34 or i==35):\n",
    "            pcn.append([0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0])\n",
    "        elif (i==2 or i==7 or i==12 or i==17 or i==22 or i==27 or i==32) :\n",
    "            pcn.append([1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1])\n",
    "        else : \n",
    "            pcn.append([1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1])\n",
    "    pcn = np.asarray(pcn)\n",
    "    return pcn\n",
    "#8x8 official\n",
    "#     for i in range(15):\n",
    "#         if (i==0 or i==4 or i==5 or i==9 or i==10 or i==14 or i==15):\n",
    "#             pcn.append([0,1,1,1,0,0,1,1,1,0,0,1,1,1,0])\n",
    "#         elif (i==2 or i==7 or i==12) :\n",
    "#             pcn.append([1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1])\n",
    "#         else : \n",
    "#             pcn.append([1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1])\n",
    "#     pcn = np.asarray(pcn)\n",
    "#     return pcn\n",
    "# for i in range(35):\n",
    "#     if (i==0 or i==4 or i==5 or i==9 or i==10 or i==14 or i==15 or i==19 or i==20 or i==24 or i==25 or i==29 or i==30 or i==34 or i==35):\n",
    "#         pcn.append([0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0])\n",
    "#     elif (i==2 or i==7 or i==12 or i==17 or i==22 or i==27 or i==32) :\n",
    "#         pcn.append([1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1,1,0.9,0.95,0.9,1])\n",
    "#     else : \n",
    "#         pcn.append([1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1,1,0.9,0.9,0.9,1])\n",
    "pcn = get_map()\n",
    "pcn = pcn.astype(float)\n",
    "pcn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 87186,
     "status": "ok",
     "timestamp": 1593147077600,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "7vAa9PvDEv0O"
   },
   "outputs": [],
   "source": [
    "visited_mark = 0.8  # Cells visited by the agent will be painted by gray 0.8\n",
    "agent_mark = 0.5      # The current agent cell will be painteg by gray 0.5\n",
    "target_mark = 0.7\n",
    "LEFT1 = 0\n",
    "LEFT2 = 1\n",
    "LEFT3 = 2\n",
    "UP1 = 3\n",
    "UP2 = 4\n",
    "UP3 = 5\n",
    "RIGHT1 = 6\n",
    "RIGHT2 = 7\n",
    "RIGHT3 = 8\n",
    "DOWN1 = 9\n",
    "DOWN2 = 10\n",
    "DOWN3 = 11\n",
    "\n",
    "# Actions dictionary\n",
    "actions_dict = {\n",
    "    LEFT1: 'left1',\n",
    "    LEFT2: 'left2',\n",
    "    LEFT3: 'left3',\n",
    "    UP1:'up1',\n",
    "    UP2:'up2',\n",
    "    UP3:'up3',\n",
    "    RIGHT1: 'right1',\n",
    "    RIGHT2: 'right2',\n",
    "    RIGHT3: 'right3',\n",
    "    DOWN1: 'down1',\n",
    "    DOWN2: 'down2',\n",
    "    DOWN3: 'down3',\n",
    "}\n",
    "state_centroid_dict = {}\n",
    "num_actions = len(actions_dict)\n",
    "MODEL_NAME = \"model\"\n",
    "# Exploagention factor\n",
    "AGGREGATE_STATS_EVERY = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 87184,
     "status": "ok",
     "timestamp": 1593147077601,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "4CA8FigBY-0o"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"D:/Research/RL/RLAChips-V11/data\")\n",
    "source_data = glob.glob(\"*.xlsx\")\n",
    "os.getcwd()\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 114515,
     "status": "ok",
     "timestamp": 1593147104943,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "EHCZqC2Rcrdb",
    "outputId": "7dabe51e-425b-4052-90ab-6344ec6868fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Lamda    Output         Loss1     Loss2     pc\n",
      "0  1.525  0.081787  3.120494e-05  0.000153  192.5\n",
      "1  1.530  0.148833  3.441380e-05  0.000243  192.5\n",
      "2  1.535  0.274497  4.577745e-05  0.001259  192.5\n",
      "3  1.540  0.481452  3.673484e-05  0.002275  192.5\n",
      "4  1.545  0.644609  9.567780e-06  0.002368  192.5\n",
      "5  1.550  0.651973  4.227260e-06  0.002534  192.5\n",
      "6  1.555  0.501727  1.284361e-06  0.002775  192.5\n",
      "7  1.560  0.292534  3.142490e-07  0.001900  192.5\n",
      "8  1.565  0.136158  1.971773e-06  0.000478  192.5\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.059389  0.000091  0.000750  184.15\n",
      "1  1.530  0.118085  0.000042  0.001807  184.15\n",
      "2  1.535  0.227252  0.000081  0.001311  184.15\n",
      "3  1.540  0.436841  0.000184  0.000703  184.15\n",
      "4  1.545  0.618331  0.000121  0.000174  184.15\n",
      "5  1.550  0.637778  0.000104  0.000162  184.15\n",
      "6  1.555  0.493877  0.000050  0.000634  184.15\n",
      "7  1.560  0.291929  0.000028  0.000859  184.15\n",
      "8  1.565  0.126916  0.000021  0.000950  184.15\n",
      "   Lamda    Output     Loss1         Loss2     pc\n",
      "0  1.525  0.079659  0.000390  1.350025e-04  174.4\n",
      "1  1.530  0.144708  0.000323  1.044313e-04  174.4\n",
      "2  1.535  0.281011  0.001153  3.742872e-05  174.4\n",
      "3  1.540  0.484184  0.001795  2.249174e-05  174.4\n",
      "4  1.545  0.645909  0.002086  6.102188e-06  174.4\n",
      "5  1.550  0.651711  0.002257  4.898336e-06  174.4\n",
      "6  1.555  0.500847  0.002230  2.051749e-06  174.4\n",
      "7  1.560  0.292534  0.001570  1.488224e-07  174.4\n",
      "8  1.565  0.134318  0.000514  1.500513e-06  174.4\n",
      "   Lamda    Output         Loss1     Loss2     pc\n",
      "0  1.525  0.250632  9.562622e-05  0.000469  311.7\n",
      "1  1.530  0.362174  8.374346e-05  0.000592  311.7\n",
      "2  1.535  0.430490  7.179215e-05  0.001974  311.7\n",
      "3  1.540  0.560135  4.273835e-05  0.002647  311.7\n",
      "4  1.545  0.660890  9.809423e-06  0.002428  311.7\n",
      "5  1.550  0.709544  4.600539e-06  0.002758  311.7\n",
      "6  1.555  0.680922  1.743077e-06  0.003767  311.7\n",
      "7  1.560  0.571186  6.135842e-07  0.003710  311.7\n",
      "8  1.565  0.445504  6.451592e-06  0.001564  311.7\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.181996  0.000280  0.002298  128.65\n",
      "1  1.530  0.287352  0.000101  0.004397  128.65\n",
      "2  1.535  0.356397  0.000127  0.002056  128.65\n",
      "3  1.540  0.508234  0.000214  0.000818  128.65\n",
      "4  1.545  0.633948  0.000124  0.000178  128.65\n",
      "5  1.550  0.694096  0.000113  0.000177  128.65\n",
      "6  1.555  0.670268  0.000068  0.000860  128.65\n",
      "7  1.560  0.570004  0.000055  0.001677  128.65\n",
      "8  1.565  0.415265  0.000070  0.003108  128.65\n",
      "   Lamda    Output     Loss1         Loss2     pc\n",
      "0  1.525  0.240851  0.001179  4.081832e-04  118.9\n",
      "1  1.530  0.335959  0.000750  2.424516e-04  118.9\n",
      "2  1.535  0.453395  0.001861  6.038908e-05  118.9\n",
      "3  1.540  0.568331  0.002106  2.640060e-05  118.9\n",
      "4  1.545  0.663568  0.002143  6.269026e-06  118.9\n",
      "5  1.550  0.709574  0.002457  5.333243e-06  118.9\n",
      "6  1.555  0.680877  0.003031  2.789251e-06  118.9\n",
      "7  1.560  0.576988  0.003097  2.935343e-07  118.9\n",
      "8  1.565  0.438961  0.001679  4.903784e-06  118.9\n",
      "   Lamda    Output         Loss1     Loss2     pc\n",
      "0  1.525  0.244112  9.313857e-05  0.000457  118.9\n",
      "1  1.530  0.352136  8.142241e-05  0.000576  118.9\n",
      "2  1.535  0.440706  7.349589e-05  0.002021  118.9\n",
      "3  1.540  0.563314  4.298086e-05  0.002662  118.9\n",
      "4  1.545  0.662222  9.829198e-06  0.002432  118.9\n",
      "5  1.550  0.709259  4.598689e-06  0.002757  118.9\n",
      "6  1.555  0.679727  1.740019e-06  0.003760  118.9\n",
      "7  1.560  0.571185  6.135832e-07  0.003710  118.9\n",
      "8  1.565  0.439485  6.364418e-06  0.001543  118.9\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.174894  0.000269  0.002208  110.55\n",
      "1  1.530  0.266553  0.000094  0.004078  110.55\n",
      "2  1.535  0.375360  0.000134  0.002165  110.55\n",
      "3  1.540  0.515670  0.000218  0.000830  110.55\n",
      "4  1.545  0.636517  0.000125  0.000179  110.55\n",
      "5  1.550  0.694125  0.000113  0.000177  110.55\n",
      "6  1.555  0.670224  0.000068  0.000860  110.55\n",
      "7  1.560  0.575795  0.000055  0.001694  110.55\n",
      "8  1.565  0.409165  0.000069  0.003062  110.55\n",
      "   Lamda    Output     Loss1         Loss2     pc\n",
      "0  1.525  0.231452  0.001133  3.922539e-04  100.8\n",
      "1  1.530  0.311642  0.000696  2.249025e-04  100.8\n",
      "2  1.535  0.477519  0.001960  6.360226e-05  100.8\n",
      "3  1.540  0.576647  0.002137  2.678690e-05  100.8\n",
      "4  1.545  0.666258  0.002151  6.294437e-06  100.8\n",
      "5  1.550  0.709604  0.002457  5.333469e-06  100.8\n",
      "6  1.555  0.680832  0.003031  2.789066e-06  100.8\n",
      "7  1.560  0.582850  0.003129  2.965163e-07  100.8\n",
      "8  1.565  0.432513  0.001654  4.831754e-06  100.8\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.046432  0.000031  0.001245  221.75\n",
      "1  1.530  0.099559  0.000265  0.007284  221.75\n",
      "2  1.535  0.212386  0.000135  0.002607  221.75\n",
      "3  1.540  0.432511  0.000222  0.014744  221.75\n",
      "4  1.545  0.612943  0.000026  0.002346  221.75\n",
      "5  1.550  0.638623  0.000010  0.000384  221.75\n",
      "6  1.555  0.489225  0.000077  0.007370  221.75\n",
      "7  1.560  0.289780  0.000045  0.001374  221.75\n",
      "8  1.565  0.122256  0.000073  0.001780  221.75\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.030780  0.000208  0.000037  202.25\n",
      "1  1.530  0.082056  0.000060  0.000075  202.25\n",
      "2  1.535  0.162602  0.000285  0.000118  202.25\n",
      "3  1.540  0.368599  0.000020  0.000075  202.25\n",
      "4  1.545  0.583370  0.000039  0.000053  202.25\n",
      "5  1.550  0.612752  0.000017  0.000037  202.25\n",
      "6  1.555  0.476591  0.000052  0.000024  202.25\n",
      "7  1.560  0.281909  0.000011  0.000003  202.25\n",
      "8  1.565  0.114558  0.000013  0.000003  202.25\n",
      "   Lamda    Output     Loss1     Loss2     pc\n",
      "0  1.525  0.039823  0.000819  0.000046  193.9\n",
      "1  1.530  0.091445  0.000046  0.000045  193.9\n",
      "2  1.535  0.163102  0.002065  0.000070  193.9\n",
      "3  1.540  0.371602  0.001379  0.000026  193.9\n",
      "4  1.545  0.585550  0.007167  0.000022  193.9\n",
      "5  1.550  0.577967  0.002390  0.000004  193.9\n",
      "6  1.555  0.380157  0.000977  0.000014  193.9\n",
      "7  1.560  0.173014  0.001094  0.000055  193.9\n",
      "8  1.565  0.051030  0.000704  0.000008  193.9\n",
      "   Lamda    Output     Loss1     Loss2   pc\n",
      "0  1.525  0.165574  0.000110  0.004438  176\n",
      "1  1.530  0.239747  0.000638  0.017541  176\n",
      "2  1.535  0.385887  0.000245  0.004736  176\n",
      "3  1.540  0.530670  0.000273  0.018090  176\n",
      "4  1.545  0.649778  0.000028  0.002487  176\n",
      "5  1.550  0.708384  0.000011  0.000425  176\n",
      "6  1.555  0.660508  0.000104  0.009950  176\n",
      "7  1.560  0.577274  0.000090  0.002738  176\n",
      "8  1.565  0.387174  0.000232  0.005637  176\n",
      "   Lamda    Output     Loss1     Loss2     pc\n",
      "0  1.525  0.109758  0.000742  0.000133  156.5\n",
      "1  1.530  0.197598  0.000143  0.000181  156.5\n",
      "2  1.535  0.295433  0.000518  0.000215  156.5\n",
      "3  1.540  0.452253  0.000024  0.000093  156.5\n",
      "4  1.545  0.618428  0.000042  0.000056  156.5\n",
      "5  1.550  0.679687  0.000019  0.000042  156.5\n",
      "6  1.555  0.643450  0.000070  0.000033  156.5\n",
      "7  1.560  0.561593  0.000022  0.000007  156.5\n",
      "8  1.565  0.362795  0.000040  0.000008  156.5\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.136736  0.002812  0.000159  148.15\n",
      "1  1.530  0.224733  0.000114  0.000111  148.15\n",
      "2  1.535  0.350805  0.004441  0.000150  148.15\n",
      "3  1.540  0.510558  0.001895  0.000036  148.15\n",
      "4  1.545  0.630971  0.007723  0.000023  148.15\n",
      "5  1.550  0.695045  0.002874  0.000004  148.15\n",
      "6  1.555  0.663911  0.001705  0.000025  148.15\n",
      "7  1.560  0.571556  0.003613  0.000181  148.15\n",
      "8  1.565  0.394142  0.005438  0.000062  148.15\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.136736  0.000091  0.003665  148.15\n",
      "1  1.530  0.224733  0.000598  0.016442  148.15\n",
      "2  1.535  0.350805  0.000223  0.004306  148.15\n",
      "3  1.540  0.510558  0.000262  0.017404  148.15\n",
      "4  1.545  0.630971  0.000027  0.002415  148.15\n",
      "5  1.550  0.695045  0.000011  0.000417  148.15\n",
      "6  1.555  0.663911  0.000105  0.010001  148.15\n",
      "7  1.560  0.571556  0.000089  0.002711  148.15\n",
      "8  1.565  0.394142  0.000237  0.005738  148.15\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.090642  0.000612  0.000109  128.65\n",
      "1  1.530  0.185224  0.000134  0.000170  128.65\n",
      "2  1.535  0.268574  0.000471  0.000195  128.65\n",
      "3  1.540  0.435113  0.000023  0.000089  128.65\n",
      "4  1.545  0.600528  0.000041  0.000054  128.65\n",
      "5  1.550  0.666888  0.000019  0.000041  128.65\n",
      "6  1.555  0.646765  0.000070  0.000033  128.65\n",
      "7  1.560  0.556030  0.000022  0.000007  128.65\n",
      "8  1.565  0.369324  0.000041  0.000008  128.65\n",
      "   Lamda    Output     Loss1     Loss2     pc\n",
      "0  1.525  0.112921  0.002322  0.000131  120.3\n",
      "1  1.530  0.210660  0.000106  0.000104  120.3\n",
      "2  1.535  0.318913  0.004037  0.000136  120.3\n",
      "3  1.540  0.491208  0.001823  0.000035  120.3\n",
      "4  1.545  0.612708  0.007499  0.000023  120.3\n",
      "5  1.550  0.681956  0.002820  0.000004  120.3\n",
      "6  1.555  0.667331  0.001714  0.000025  120.3\n",
      "7  1.560  0.565894  0.003577  0.000179  120.3\n",
      "8  1.565  0.401235  0.005536  0.000063  120.3\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.078807  0.000088  0.000184  128.65\n",
      "1  1.530  0.145792  0.000058  0.000077  128.65\n",
      "2  1.535  0.275556  0.000108  0.000378  128.65\n",
      "3  1.540  0.485651  0.000082  0.000523  128.65\n",
      "4  1.545  0.649450  0.000017  0.000274  128.65\n",
      "5  1.550  0.657555  0.000004  0.000083  128.65\n",
      "6  1.555  0.509597  0.000004  0.000027  128.65\n",
      "7  1.560  0.299486  0.000002  0.000112  128.65\n",
      "8  1.565  0.138812  0.000003  0.000293  128.65\n",
      "   Lamda    Output     Loss1     Loss2     pc\n",
      "0  1.525  0.060874  0.000444  0.000186  156.5\n",
      "1  1.530  0.118949  0.001315  0.000358  156.5\n",
      "2  1.535  0.249190  0.000754  0.000286  156.5\n",
      "3  1.540  0.458584  0.000800  0.000191  156.5\n",
      "4  1.545  0.635189  0.000214  0.000091  156.5\n",
      "5  1.550  0.654061  0.000142  0.000066  156.5\n",
      "6  1.555  0.500125  0.000621  0.000024  156.5\n",
      "7  1.560  0.290879  0.000916  0.000015  156.5\n",
      "8  1.565  0.131996  0.000953  0.000024  156.5\n",
      "   Lamda    Output     Loss1         Loss2     pc\n",
      "0  1.525  0.070708  0.000300  3.425167e-04  100.8\n",
      "1  1.530  0.131862  0.000144  1.966190e-04  100.8\n",
      "2  1.535  0.289799  0.000793  1.437102e-04  100.8\n",
      "3  1.540  0.491905  0.000777  8.633561e-05  100.8\n",
      "4  1.545  0.651789  0.000612  1.868983e-05  100.8\n",
      "5  1.550  0.657067  0.000400  4.513758e-06  100.8\n",
      "6  1.555  0.509041  0.000265  8.937343e-07  100.8\n",
      "7  1.560  0.300147  0.000401  1.357330e-06  100.8\n",
      "8  1.565  0.138316  0.000387  2.669397e-06  100.8\n",
      "   Lamda    Output     Loss1     Loss2     pc\n",
      "0  1.525  0.228161  0.000931  0.000631  120.3\n",
      "1  1.530  0.329369  0.001126  0.000234  120.3\n",
      "2  1.535  0.453637  0.000111  0.000433  120.3\n",
      "3  1.540  0.569818  0.000083  0.000557  120.3\n",
      "4  1.545  0.668100  0.000008  0.000227  120.3\n",
      "5  1.550  0.715921  0.000038  0.000047  120.3\n",
      "6  1.555  0.690833  0.000031  0.000038  120.3\n",
      "7  1.560  0.585185  0.000163  0.000210  120.3\n",
      "8  1.565  0.432609  0.000272  0.000996  120.3\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.199797  0.001458  0.000609  148.15\n",
      "1  1.530  0.296867  0.003283  0.000894  148.15\n",
      "2  1.535  0.391366  0.001184  0.000449  148.15\n",
      "3  1.540  0.534454  0.000932  0.000223  148.15\n",
      "4  1.545  0.651524  0.000220  0.000093  148.15\n",
      "5  1.550  0.712375  0.000154  0.000072  148.15\n",
      "6  1.555  0.679444  0.000844  0.000033  148.15\n",
      "7  1.560  0.572461  0.001803  0.000030  148.15\n",
      "8  1.565  0.427069  0.003082  0.000077  148.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.232075  0.000985  0.001124  128.65\n",
      "1  1.530  0.329094  0.000359  0.000491  128.65\n",
      "2  1.535  0.455145  0.001246  0.000226  128.65\n",
      "3  1.540  0.573287  0.000906  0.000101  128.65\n",
      "4  1.545  0.668551  0.000627  0.000019  128.65\n",
      "5  1.550  0.715649  0.000436  0.000005  128.65\n",
      "6  1.555  0.691557  0.000360  0.000001  128.65\n",
      "7  1.560  0.590700  0.000789  0.000003  128.65\n",
      "8  1.565  0.447518  0.001251  0.000009  128.65\n",
      "   Lamda    Output     Loss1     Loss2      pc\n",
      "0  1.525  0.232075  0.000259  0.000541  202.25\n",
      "1  1.530  0.329094  0.000131  0.000174  202.25\n",
      "2  1.535  0.455145  0.000178  0.000624  202.25\n",
      "3  1.540  0.573287  0.000097  0.000617  202.25\n",
      "4  1.545  0.668551  0.000018  0.000282  202.25\n",
      "5  1.550  0.715649  0.000004  0.000090  202.25\n",
      "6  1.555  0.691557  0.000005  0.000036  202.25\n",
      "7  1.560  0.590700  0.000004  0.000222  202.25\n",
      "8  1.565  0.447518  0.000010  0.000945  202.25\n",
      "   Lamda    Output     Loss1     Loss2     pc\n",
      "0  1.525  0.179265  0.001308  0.000547  230.1\n",
      "1  1.530  0.268502  0.002969  0.000809  230.1\n",
      "2  1.535  0.411594  0.001245  0.000472  230.1\n",
      "3  1.540  0.541336  0.000944  0.000226  230.1\n",
      "4  1.545  0.653871  0.000221  0.000094  230.1\n",
      "5  1.550  0.711846  0.000154  0.000072  230.1\n",
      "6  1.555  0.678702  0.000843  0.000033  230.1\n",
      "7  1.560  0.573724  0.001807  0.000030  230.1\n",
      "8  1.565  0.425544  0.003071  0.000077  230.1\n",
      "   Lamda    Output     Loss1     Loss2     pc\n",
      "0  1.525  0.208227  0.000884  0.001009  174.4\n",
      "1  1.530  0.297650  0.000325  0.000444  174.4\n",
      "2  1.535  0.478670  0.001310  0.000237  174.4\n",
      "3  1.540  0.580670  0.000917  0.000102  174.4\n",
      "4  1.545  0.670959  0.000629  0.000019  174.4\n",
      "5  1.550  0.715118  0.000436  0.000005  174.4\n",
      "6  1.555  0.690802  0.000359  0.000001  174.4\n",
      "7  1.560  0.592003  0.000791  0.000003  174.4\n",
      "8  1.565  0.445920  0.001247  0.000009  174.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'I1_to_J1': -0.060831490630537596,\n",
       " 'I1_to_J2': -0.07039157926195691,\n",
       " 'I1_to_J3': -0.06100618220166166,\n",
       " 'I1_to_K1': -0.024081738085422133,\n",
       " 'I1_to_K2': -0.03364182671684155,\n",
       " 'I1_to_K3': -0.024063378362385385,\n",
       " 'I1_to_O1': -0.02425642965654643,\n",
       " 'I1_to_O2': -0.033623466993804786,\n",
       " 'I1_to_O3': -0.02404501863934866,\n",
       " 'I2_to_J1': -0.06981675080087654,\n",
       " 'I2_to_J2': -0.08777659117674864,\n",
       " 'I2_to_J3': -0.11315846891863693,\n",
       " 'I2_to_K1': -0.024792541608285847,\n",
       " 'I2_to_K2': -0.042752381984157935,\n",
       " 'I2_to_K3': -0.03304863853272445,\n",
       " 'I2_to_O1': -0.03304863853272445,\n",
       " 'I2_to_O2': -0.05100847890859658,\n",
       " 'I2_to_O3': -0.041304735457163115,\n",
       " 'I3_to_J1': -0.05712925782497559,\n",
       " 'I3_to_J2': -0.0594432556682023,\n",
       " 'I3_to_J3': -0.057451647401003184,\n",
       " 'I3_to_K1': -0.02019621511126152,\n",
       " 'I3_to_K2': -0.02235275382402254,\n",
       " 'I3_to_K3': -0.020361145556823387,\n",
       " 'I3_to_O1': -0.020361145556823536,\n",
       " 'I3_to_O2': -0.02267514340005018,\n",
       " 'I3_to_O3': -0.02068353513285113}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = {}\n",
    "pc={}\n",
    "for file in source_data :\n",
    "  data = pd.read_excel(file,header=0)\n",
    "  print(data)\n",
    "  row = data.loc[data['Lamda']==1.5500].values[0][1:]\n",
    "  file_name = file.split('.')[0]\n",
    "  output_loss = row[0]\n",
    "  power_cons = row[3]\n",
    "  #print(output_loss)\n",
    "  df[file_name] = np.log10(output_loss*4/3)\n",
    "  pc[file_name] = power_cons\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I1_to_J1': 192.5,\n",
       " 'I1_to_J2': 184.15,\n",
       " 'I1_to_J3': 174.4,\n",
       " 'I1_to_K1': 311.7,\n",
       " 'I1_to_K2': 128.65,\n",
       " 'I1_to_K3': 118.9,\n",
       " 'I1_to_O1': 118.9,\n",
       " 'I1_to_O2': 110.55,\n",
       " 'I1_to_O3': 100.8,\n",
       " 'I2_to_J1': 221.75,\n",
       " 'I2_to_J2': 202.25,\n",
       " 'I2_to_J3': 193.9,\n",
       " 'I2_to_K1': 176.0,\n",
       " 'I2_to_K2': 156.5,\n",
       " 'I2_to_K3': 148.15,\n",
       " 'I2_to_O1': 148.15,\n",
       " 'I2_to_O2': 128.65,\n",
       " 'I2_to_O3': 120.3,\n",
       " 'I3_to_J1': 128.65,\n",
       " 'I3_to_J2': 156.5,\n",
       " 'I3_to_J3': 100.8,\n",
       " 'I3_to_K1': 120.3,\n",
       " 'I3_to_K2': 148.15,\n",
       " 'I3_to_K3': 128.65,\n",
       " 'I3_to_O1': 202.25,\n",
       " 'I3_to_O2': 230.1,\n",
       " 'I3_to_O3': 174.4}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "pc[\"K1_to_O1\"]=pc[\"O1_to_K1\"]=pc[\"J1_to_I3\"]=pc[\"I3_to_J1\"]\n",
    "pc[\"K1_to_O2\"]=pc[\"O1_to_K2\"]=pc[\"J1_to_I2\"]=pc[\"I3_to_J2\"]\n",
    "pc[\"K1_to_O3\"]=pc[\"O1_to_K3\"]=pc[\"J1_to_I1\"]=pc[\"I3_to_J3\"]\n",
    "pc[\"K1_to_J1\"]=pc[\"O1_to_I3\"]=pc[\"J1_to_O1\"]=pc[\"I3_to_K1\"]\n",
    "pc[\"K1_to_J2\"]=pc[\"O1_to_I2\"]=pc[\"J1_to_O2\"]=pc[\"I3_to_K2\"]\n",
    "pc[\"K1_to_J3\"]=pc[\"O1_to_I1\"]=pc[\"J1_to_O3\"]=pc[\"I3_to_K3\"]\n",
    "pc[\"K1_to_I3\"]=pc[\"O1_to_J1\"]=pc[\"J1_to_K1\"]=pc[\"I3_to_O1\"]\n",
    "pc[\"K1_to_I2\"]=pc[\"O1_to_J2\"]=pc[\"J1_to_K2\"]=pc[\"I3_to_O2\"]\n",
    "pc[\"K1_to_I1\"]=pc[\"O1_to_J3\"]=pc[\"J1_to_K3\"]=pc[\"I3_to_O3\"]\n",
    "###########################################################\n",
    "pc[\"K3_to_O1\"]=pc[\"O3_to_K1\"]=pc[\"J3_to_I3\"]=pc[\"I1_to_J1\"]\n",
    "pc[\"K3_to_O2\"]=pc[\"O3_to_K2\"]=pc[\"J3_to_I2\"]=pc[\"I1_to_J2\"]\n",
    "pc[\"K3_to_O3\"]=pc[\"O3_to_K3\"]=pc[\"J3_to_I1\"]=pc[\"I1_to_J3\"]\n",
    "pc[\"K3_to_J1\"]=pc[\"O3_to_I3\"]=pc[\"J3_to_O1\"]=pc[\"I1_to_K1\"]\n",
    "pc[\"K3_to_J2\"]=pc[\"O3_to_I2\"]=pc[\"J3_to_O2\"]=pc[\"I1_to_K2\"]\n",
    "pc[\"K3_to_J3\"]=pc[\"O3_to_I1\"]=pc[\"J3_to_O3\"]=pc[\"I1_to_K3\"]\n",
    "pc[\"K3_to_I3\"]=pc[\"O3_to_J1\"]=pc[\"J3_to_K1\"]=pc[\"I1_to_O1\"]\n",
    "pc[\"K3_to_I2\"]=pc[\"O3_to_J2\"]=pc[\"J3_to_K2\"]=pc[\"I1_to_O2\"]\n",
    "pc[\"K3_to_I1\"]=pc[\"O3_to_J3\"]=pc[\"J3_to_K3\"]=pc[\"I1_to_O3\"]\n",
    "###########################################################\n",
    "pc[\"K2_to_O1\"]=pc[\"O2_to_K1\"]=pc[\"J2_to_I3\"]=pc[\"I2_to_J1\"]\n",
    "pc[\"K2_to_O2\"]=pc[\"O2_to_K2\"]=pc[\"J2_to_I2\"]=pc[\"I2_to_J2\"]\n",
    "pc[\"K2_to_O3\"]=pc[\"O2_to_K3\"]=pc[\"J2_to_I1\"]=pc[\"I2_to_J3\"]\n",
    "pc[\"K2_to_J1\"]=pc[\"O2_to_I3\"]=pc[\"J2_to_O1\"]=pc[\"I2_to_K1\"]\n",
    "pc[\"K2_to_J2\"]=pc[\"O2_to_I2\"]=pc[\"J2_to_O2\"]=pc[\"I2_to_K2\"]\n",
    "pc[\"K2_to_J3\"]=pc[\"O2_to_I1\"]=pc[\"J2_to_O3\"]=pc[\"I2_to_K3\"]\n",
    "pc[\"K2_to_I3\"]=pc[\"O2_to_J1\"]=pc[\"J2_to_K1\"]=pc[\"I2_to_O1\"]\n",
    "pc[\"K2_to_I2\"]=pc[\"O2_to_J2\"]=pc[\"J2_to_K2\"]=pc[\"I2_to_O2\"]\n",
    "pc[\"K2_to_I1\"]=pc[\"O2_to_J3\"]=pc[\"J2_to_K3\"]=pc[\"I2_to_O3\"]\n",
    "###########################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 114505,
     "status": "ok",
     "timestamp": 1593147104944,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "5iYmR0Anxm0w",
    "outputId": "a0266052-6466-405a-c2b7-c3d5468c0ba4"
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "df[\"K1_to_O1\"]=df[\"O1_to_K1\"]=df[\"J1_to_I3\"]=df[\"I3_to_J1\"]\n",
    "df[\"K1_to_O2\"]=df[\"O1_to_K2\"]=df[\"J1_to_I2\"]=df[\"I3_to_J2\"]\n",
    "df[\"K1_to_O3\"]=df[\"O1_to_K3\"]=df[\"J1_to_I1\"]=df[\"I3_to_J3\"]\n",
    "df[\"K1_to_J1\"]=df[\"O1_to_I3\"]=df[\"J1_to_O1\"]=df[\"I3_to_K1\"]\n",
    "df[\"K1_to_J2\"]=df[\"O1_to_I2\"]=df[\"J1_to_O2\"]=df[\"I3_to_K2\"]\n",
    "df[\"K1_to_J3\"]=df[\"O1_to_I1\"]=df[\"J1_to_O3\"]=df[\"I3_to_K3\"]\n",
    "df[\"K1_to_I3\"]=df[\"O1_to_J1\"]=df[\"J1_to_K1\"]=df[\"I3_to_O1\"]\n",
    "df[\"K1_to_I2\"]=df[\"O1_to_J2\"]=df[\"J1_to_K2\"]=df[\"I3_to_O2\"]\n",
    "df[\"K1_to_I1\"]=df[\"O1_to_J3\"]=df[\"J1_to_K3\"]=df[\"I3_to_O3\"]\n",
    "###########################################################\n",
    "df[\"K3_to_O1\"]=df[\"O3_to_K1\"]=df[\"J3_to_I3\"]=df[\"I1_to_J1\"]\n",
    "df[\"K3_to_O2\"]=df[\"O3_to_K2\"]=df[\"J3_to_I2\"]=df[\"I1_to_J2\"]\n",
    "df[\"K3_to_O3\"]=df[\"O3_to_K3\"]=df[\"J3_to_I1\"]=df[\"I1_to_J3\"]\n",
    "df[\"K3_to_J1\"]=df[\"O3_to_I3\"]=df[\"J3_to_O1\"]=df[\"I1_to_K1\"]\n",
    "df[\"K3_to_J2\"]=df[\"O3_to_I2\"]=df[\"J3_to_O2\"]=df[\"I1_to_K2\"]\n",
    "df[\"K3_to_J3\"]=df[\"O3_to_I1\"]=df[\"J3_to_O3\"]=df[\"I1_to_K3\"]\n",
    "df[\"K3_to_I3\"]=df[\"O3_to_J1\"]=df[\"J3_to_K1\"]=df[\"I1_to_O1\"]\n",
    "df[\"K3_to_I2\"]=df[\"O3_to_J2\"]=df[\"J3_to_K2\"]=df[\"I1_to_O2\"]\n",
    "df[\"K3_to_I1\"]=df[\"O3_to_J3\"]=df[\"J3_to_K3\"]=df[\"I1_to_O3\"]\n",
    "###########################################################\n",
    "df[\"K2_to_O1\"]=df[\"O2_to_K1\"]=df[\"J2_to_I3\"]=df[\"I2_to_J1\"]\n",
    "df[\"K2_to_O2\"]=df[\"O2_to_K2\"]=df[\"J2_to_I2\"]=df[\"I2_to_J2\"]\n",
    "df[\"K2_to_O3\"]=df[\"O2_to_K3\"]=df[\"J2_to_I1\"]=df[\"I2_to_J3\"]\n",
    "df[\"K2_to_J1\"]=df[\"O2_to_I3\"]=df[\"J2_to_O1\"]=df[\"I2_to_K1\"]\n",
    "df[\"K2_to_J2\"]=df[\"O2_to_I2\"]=df[\"J2_to_O2\"]=df[\"I2_to_K2\"]\n",
    "df[\"K2_to_J3\"]=df[\"O2_to_I1\"]=df[\"J2_to_O3\"]=df[\"I2_to_K3\"]\n",
    "df[\"K2_to_I3\"]=df[\"O2_to_J1\"]=df[\"J2_to_K1\"]=df[\"I2_to_O1\"]\n",
    "df[\"K2_to_I2\"]=df[\"O2_to_J2\"]=df[\"J2_to_K2\"]=df[\"I2_to_O2\"]\n",
    "df[\"K2_to_I1\"]=df[\"O2_to_J3\"]=df[\"J2_to_K3\"]=df[\"I2_to_O3\"]\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 114494,
     "status": "ok",
     "timestamp": 1593147104944,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "S46aKVGw-1b8",
    "outputId": "375e1a25-7796-468b-fd9d-a33982d439b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.024063378362385385"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_node_dict = {}\n",
    "action_node_dict[LEFT1]='K1'\n",
    "action_node_dict[LEFT2]='K2'\n",
    "action_node_dict[LEFT3]='K3'\n",
    "action_node_dict[UP1]='J1'\n",
    "action_node_dict[UP2]='J2'\n",
    "action_node_dict[UP3]='J3'\n",
    "action_node_dict[RIGHT1]='O1'\n",
    "action_node_dict[RIGHT2]='O2'\n",
    "action_node_dict[RIGHT3]='O3'\n",
    "action_node_dict[DOWN1]='I1'\n",
    "action_node_dict[DOWN2]='I2'\n",
    "action_node_dict[DOWN3]='I3'\n",
    "df[\"{}_to_{}\".format(action_node_dict[DOWN1],action_node_dict[LEFT3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy(noise_typ,image):\n",
    "    if noise_typ == \"gauss\":\n",
    "      row,col= image.shape\n",
    "      mean = 0\n",
    "      var = 0.01\n",
    "      sigma = var**0.6\n",
    "      gauss = np.random.uniform(low = mean,high = sigma,size = row*col)\n",
    "      gauss = gauss.reshape(row,col)\n",
    "      noisy = image + gauss\n",
    "      return noisy\n",
    "    elif noise_typ == \"s&p\":\n",
    "      row,col = image.shape\n",
    "      s_vs_p = 0.5\n",
    "      amount = 0.004\n",
    "      out = np.copy(image)\n",
    "      # Salt mode\n",
    "      num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "      coords = [np.random.randint(0, i - 1, int(num_salt))\n",
    "              for i in image.shape]\n",
    "      out[coords] = 1\n",
    "\n",
    "      # Pepper mode\n",
    "      num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "      coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
    "              for i in image.shape]\n",
    "      out[coords] = 0\n",
    "      return out\n",
    "    elif noise_typ == \"poisson\":\n",
    "      vals = len(np.unique(image))\n",
    "      vals = 2 ** np.ceil(np.log2(vals))\n",
    "      noisy = np.random.poisson(image * vals) / float(vals)\n",
    "      return noisy\n",
    "    elif noise_typ ==\"speckle\":\n",
    "      row,col = image.shape\n",
    "      gauss = np.random.randn(row,col)\n",
    "      gauss = gauss.reshape(row,col)        \n",
    "      noisy = image + image * gauss\n",
    "      return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 117610,
     "status": "ok",
     "timestamp": 1593147108063,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "DQzW46P1Ewo7"
   },
   "outputs": [],
   "source": [
    "# pcn is a 2d Numpy array of floats between 0.0 to 1.0\n",
    "# 1.0 corresponds to a free cell, and 0.0 an occupied cell\n",
    "# agent = (row, col) initial agent position (defaults to (0,0))\n",
    "\n",
    "class Qpcn(object):\n",
    "    def __init__(self, pcn, agent=(0,1)):\n",
    "        self._pcn = np.array(pcn)\n",
    "        nrows, ncols = self._pcn.shape\n",
    "        self.target = (nrows-1,ncols-2) # target cell where the \"cheese\" is\n",
    "        self.free_cells = [(r,c) for r in range(nrows) for c in range(ncols) if self._pcn[r,c] == 1.0 ]\n",
    "        self.free_target_cells = []\n",
    "        for r in range(nrows):\n",
    "            for c in range(ncols):\n",
    "                if self._pcn[r,c] == 1.0 :\n",
    "                    if r == 0 or r == nrows-1 or c == 0 or c == ncols-1:\n",
    "                        self.free_target_cells.append((r,c))\n",
    "#                     if r == nrows-1 :\n",
    "#                         self.free_target_cells.append((r,c))\n",
    "        self.free_cells.remove(self.target)\n",
    "        self.current_distance = None\n",
    "        self.available_cell_target = []\n",
    "        self.centroid = []\n",
    "        self.supervised = 0\n",
    "        self.old_action = 1\n",
    "        self.current_action = None\n",
    "        self.num_non_available_cell = 30\n",
    "        self.state_dim = self.num_non_available_cell*2+4\n",
    "        if self._pcn[self.target] == 0.0:\n",
    "            raise Exception(\"Invalid pcn: target cell cannot be blocked!\")\n",
    "        if not agent in self.free_cells:\n",
    "            raise Exception(\"Invalid agent Location: must sit on a free cell\")\n",
    "        self.non_available_cell = random.choices(self.free_cells,k=self.num_non_available_cell)\n",
    "        self.reset(agent,self.target,self.non_available_cell)\n",
    "    def get_list_centroid(self):\n",
    "      dx=[0,2,0,-2,   -2,-1,2,1,    -2,1,2,-1]\n",
    "      dy=[2,0,-2,0,   -1,2,1,-2,    1,2,-1,-2]\n",
    "      for i in range (self._pcn.shape[0]):\n",
    "        for j in range (self._pcn.shape[1]):\n",
    "          if (self._pcn[i][j]==0.95) :\n",
    "            self.centroid.append((i,j))\n",
    "            for temp in range(12):\n",
    "              tx = i + dx[temp]\n",
    "              ty = j + dy[temp]\n",
    "              state_centroid_dict[(tx,ty)] = (i,j)\n",
    "    def available_cell_for_agent(self):\n",
    "        list_available_cell_agent = []\n",
    "        nrows, ncols = self._pcn.shape\n",
    "        for row in range(nrows) :\n",
    "            for col in range(ncols) :\n",
    "              if row == 1 or row == 2 or row == 3 or row ==6 or row == 7 or row ==8 or row == 11 or row == 12 or row == 13 :\n",
    "                if col == 0 or col == 14 :\n",
    "                      list_available_cell_agent.append((row,col))\n",
    "              if col== 1 or col == 2 or col == 3 or col ==6 or col == 7 or col ==8 or col == 11 or col == 12 or col == 13 :\n",
    "                if row == 0 or row == 14 :\n",
    "                      list_available_cell_agent.append((row,col))\n",
    "                if row == nrows-1 :\n",
    "                      self.available_cell_target.append((row,col))\n",
    "        return list_available_cell_agent\n",
    "    \n",
    "    def reset(self, agent,target,non_available_cell):\n",
    "        self.agent = agent\n",
    "        self._pcn = get_map()\n",
    "        nrows, ncols = self._pcn.shape\n",
    "        row, col = agent\n",
    "        self._pcn[row, col] = agent_mark\n",
    "        self.state = (row, col, 'valid')\n",
    "        self.min_reward = -256\n",
    "        self.total_reward = 0\n",
    "        self.visited = set()\n",
    "        self.target = target\n",
    "        target_row,target_col = self.target\n",
    "        self.old_distance = -999\n",
    "        self.list_previous_state=[]\n",
    "        self.non_available_cell = non_available_cell\n",
    "        return self.observe().reshape(1,self.state_dim)\n",
    "    def check_state_centroid(self):\n",
    "      nrow, ncol, nmode = agent_row, agent_col, mode = self.state\n",
    "\n",
    "\n",
    "    def update_state(self, action):\n",
    "        nrows, ncols = self._pcn.shape\n",
    "        nrow, ncol, nmode = agent_row, agent_col, mode = self.state\n",
    "        if self._pcn[agent_row, agent_col] > 0:\n",
    "            self.visited.add((agent_row, agent_col))  # mark visited cell\n",
    "\n",
    "        valid_actions = self.valid_actions()\n",
    "        x_centroid,y_centroid = state_centroid_dict[(nrow, ncol)]\n",
    "        if not valid_actions:\n",
    "            nmode = 'blocked'\n",
    "        elif action in valid_actions:\n",
    "            nmode = 'valid'\n",
    "            dx=[0,2,0,-2,   -2,-1,2,1,    -2,1,2,-1]\n",
    "            dy=[2,0,-2,0,   -1,2,1,-2,    1,2,-1,-2]\n",
    "            #r2,d2,l2,u2,u1,r1,d3,l3,u3,r3,d1,l1\n",
    "            #0 ,1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10 ,11\n",
    "            if action == LEFT1:\n",
    "              if self._pcn[nrow][ncol-1]== 1 and self._pcn[nrow][ncol+1]== 0.9:\n",
    "                x_centroid +=dx[11]\n",
    "                y_centroid +=(dy[11]-1)\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[11]\n",
    "                y_centroid +=dy[11]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == LEFT2:\n",
    "              if self._pcn[nrow][ncol-1]== 1 and self._pcn[nrow][ncol+1]== 0.9:\n",
    "                x_centroid +=dx[2]\n",
    "                y_centroid +=(dy[2]-1)\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[2]\n",
    "                y_centroid +=dy[2]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == LEFT3:\n",
    "              if self._pcn[nrow][ncol-1]== 1 and self._pcn[nrow][ncol+1]== 0.9:\n",
    "                x_centroid +=dx[7]\n",
    "                y_centroid +=(dy[7]-1)\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[7]\n",
    "                y_centroid +=dy[7]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == RIGHT1:\n",
    "              if self._pcn[nrow][ncol+1]== 1 and self._pcn[nrow][ncol-1]== 0.9:\n",
    "                x_centroid +=dx[5]\n",
    "                y_centroid +=(dy[5]+1)\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[5]\n",
    "                y_centroid +=dy[5]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == RIGHT2:\n",
    "              if self._pcn[nrow][ncol+1]== 1 and self._pcn[nrow][ncol-1]== 0.9:\n",
    "                x_centroid +=dx[0]\n",
    "                y_centroid +=(dy[0]+1)\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[0]\n",
    "                y_centroid +=dy[0]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == RIGHT3:\n",
    "              if self._pcn[nrow][ncol+1]== 1 and self._pcn[nrow][ncol-1]== 0.9:\n",
    "                x_centroid +=dx[9]\n",
    "                y_centroid +=(dy[9]+1)\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[9]\n",
    "                y_centroid +=dy[9]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == DOWN1:\n",
    "              if self._pcn[nrow+1][ncol]== 1 and self._pcn[nrow-1][ncol]== 0.9:\n",
    "                x_centroid +=(dx[10]+1)\n",
    "                y_centroid +=dy[10]\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[10]\n",
    "                y_centroid +=dy[10]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == DOWN2:\n",
    "              if self._pcn[nrow+1][ncol]== 1 and self._pcn[nrow-1][ncol]== 0.9:\n",
    "                x_centroid +=(dx[1]+1)\n",
    "                y_centroid +=dy[1]\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[1]\n",
    "                y_centroid +=dy[1]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == DOWN3:\n",
    "              if self._pcn[nrow+1][ncol]== 1 and self._pcn[nrow-1][ncol]== 0.9:\n",
    "                x_centroid +=(dx[6]+1)\n",
    "                y_centroid +=dy[6]\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[6]\n",
    "                y_centroid +=dy[6]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == UP1:\n",
    "              if self._pcn[nrow-1][ncol]== 1 and self._pcn[nrow+1][ncol]== 0.9:\n",
    "                x_centroid +=(dx[4]-1)\n",
    "                y_centroid +=dy[4]\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[4]\n",
    "                y_centroid +=dy[4]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == UP2:\n",
    "              if self._pcn[nrow-1][ncol]== 1 and self._pcn[nrow+1][ncol]== 0.9:\n",
    "                x_centroid +=(dx[3]-1)\n",
    "                y_centroid +=dy[3]\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[3]\n",
    "                y_centroid +=dy[3]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == UP3:\n",
    "              if self._pcn[nrow-1][ncol]== 1 and self._pcn[nrow+1][ncol]== 0.9:\n",
    "                x_centroid +=(dx[8]-1)\n",
    "                y_centroid +=dy[8]\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[8]\n",
    "                y_centroid +=dy[8]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "        else:                  # invalid action, no change in agent position\n",
    "            #nmode = 'invalid'\n",
    "            pass\n",
    "\n",
    "    def get_reward(self):\n",
    "        agent_row, agent_col, mode = self.state\n",
    "        target_row,target_col = self.target\n",
    "        nrows, ncols = self._pcn.shape\n",
    "        reward = None\n",
    "        status = None\n",
    "        if mode == 'reward_unchanged'and not (agent_row, agent_col) in self.visited:\n",
    "          #mode = \"valid\"\n",
    "          return 0\n",
    "#         if self.current_action == self.old_action :\n",
    "#           return -1.2\n",
    "        if mode == 'blocked':\n",
    "            reward  =self.min_reward - 0.5\n",
    "        if (agent_row, agent_col) in self.visited:\n",
    "            return -1.5\n",
    "        if mode == 'invalid':\n",
    "            reward  = -2\n",
    "        # if mode == 'valid':\n",
    "        #     reward  = -0.04\n",
    "        if mode == 'valid':\n",
    "            # self.current_distance = self.dist(agent_row,agent_col,target_row,target_col)\n",
    "            # if self.current_distance <= self.old_distance :\n",
    "            #       reward = -self.current_distance*0.004\n",
    "                  \n",
    "            # else : reward = -self.current_distance*0.005\n",
    "            # self.old_distance = self.current_distance\n",
    "            try : \n",
    "              reward = df[\"{}_to_{}\".format(action_node_dict[self.old_action],action_node_dict[self.current_action])]\n",
    "            except :\n",
    "              reward = -1\n",
    "        if agent_row == target_row and agent_col == target_col:\n",
    "            status = 'win'\n",
    "            return 2\n",
    "        # if mode == 'valid' and status !='win':\n",
    "        #       self.current_distance = self.dist(agent_row,agent_col,target_row,target_col)\n",
    "        #       if (agent_row, agent_col) in self.visited :\n",
    "        #           reward = -0.25\n",
    "        #       elif self.current_distance >= self.old_distance :\n",
    "        #       #reward = -current_distance*0.001\n",
    "        #           reward = -0.1             \n",
    "        #       else : reward = -0.04\n",
    "        #       self.old_distance = self.current_distance\n",
    "        return reward\n",
    "    def dist(self,x1,y1,x2,y2):\n",
    "        return ((x2-x1)**2 + (y2-y1)**2)**0.5\n",
    "    def act(self, action):\n",
    "        self.update_state(action)\n",
    "        reward = self.get_reward()\n",
    "        self.total_reward += reward\n",
    "        status = self.game_status()\n",
    "        envstate = self.observe()\n",
    "        return envstate, reward, status\n",
    "    def act_to_predict(self, action):\n",
    "        self.update_state_to_predict(action)\n",
    "        status = self.game_status_to_predict()\n",
    "        envstate = self.observe()\n",
    "        return envstate, status\n",
    "\n",
    "    def observe(self):\n",
    "        canvas = self.draw_env(self.non_available_cell)\n",
    "        envstate = np.reshape(canvas,newshape=(1,self.state_dim))\n",
    "        return envstate\n",
    "\n",
    "    def draw_env(self, non_available_cell):\n",
    "        self._pcn = get_map()\n",
    "        row, col = self.agent\n",
    "        self._pcn[row, col] = agent_mark\n",
    "        canvas = np.copy(self._pcn)\n",
    "        nrows, ncols = self._pcn.shape\n",
    "        # clear all visual marks\n",
    "        for r in range(nrows):\n",
    "            for c in range(ncols):\n",
    "                if canvas[r,c] > 0.0:\n",
    "                    canvas[r,c] = 1.0\n",
    "                if (r,c) in  non_available_cell:\n",
    "                    canvas[r,c] = 0.0\n",
    "                    self._pcn[r,c]= 0.0\n",
    "        # draw the agent\n",
    "        for row,col in self.visited:\n",
    "            canvas[row,col] = 0.6\n",
    "        row, col, valid = self.state\n",
    "        row_target,col_target =  self.target\n",
    "        canvas[row, col] = agent_mark\n",
    "        canvas[row_target,col_target] = target_mark\n",
    "        #canvas = noisy(\"gauss\",canvas)\n",
    "        input_state = [row,col,row_target,col_target]\n",
    "        for item in non_available_cell:\n",
    "            input_state.append(item[0])\n",
    "            input_state.append(item[1])\n",
    "        input_state = np.asarray(input_state).reshape(-1, 1)\n",
    "        std_scale = preprocessing.StandardScaler().fit(input_state)\n",
    "        input_state = std_scale.transform(input_state)\n",
    "        return input_state\n",
    "\n",
    "    def game_status(self):\n",
    "        if self.total_reward < self.min_reward:\n",
    "            return 'lose'\n",
    "        agent_row, agent_col, mode = self.state\n",
    "        nrows, ncols = self._pcn.shape\n",
    "        target_row,target_col = self.target\n",
    "        if agent_row == target_row and agent_col == target_col:\n",
    "            return 'win'\n",
    "\n",
    "        return 'not_over'\n",
    "    def set_supervised(self,supervised):\n",
    "        self.supervised = supervised \n",
    "    def game_status_to_predict(self):\n",
    "        agent_row, agent_col, mode = self.state\n",
    "        target_row,target_col = self.target\n",
    "        if agent_row == target_row and agent_col == target_col:\n",
    "            return 'win'\n",
    "\n",
    "        return 'not_over'\n",
    "\n",
    "    def valid_actions(self, cell=None):\n",
    "        if cell is None:\n",
    "            row, col, mode = self.state\n",
    "        else:\n",
    "            row, col = cell\n",
    "        actions = [LEFT1, LEFT2, LEFT3, RIGHT1, RIGHT2, RIGHT3, UP1, UP2, UP3, DOWN1, DOWN2, DOWN3]\n",
    "        nrows, ncols = self._pcn.shape\n",
    "        if row == 0:\n",
    "            actions.remove(UP1)\n",
    "            actions.remove(UP2)\n",
    "            actions.remove(UP3)\n",
    "        elif row == nrows-1:\n",
    "            actions.remove(DOWN1)\n",
    "            actions.remove(DOWN2)\n",
    "            actions.remove(DOWN3)\n",
    "        if col == 0:\n",
    "            actions.remove(LEFT1)\n",
    "            actions.remove(LEFT2)\n",
    "            actions.remove(LEFT3)\n",
    "        elif col == ncols-1:\n",
    "            actions.remove(RIGHT1)\n",
    "            actions.remove(RIGHT2)\n",
    "            actions.remove(RIGHT3)\n",
    "        dx=[0,2,0,-2,   -2,-1,2,1,    -2,1,2,-1]\n",
    "        dy=[2,0,-2,0,   -1,2,1,-2,    1,2,-1,-2]\n",
    "        #r2,d2,l2,u2,u1,r1,d3,l3,u3,r3,d1,l1\n",
    "        #0 ,1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10 ,11\n",
    "        tx_target,ty_target = self.target\n",
    "        if self.supervised == 1:\n",
    "            best_choice = None\n",
    "            best_distance = 999999\n",
    "            for action in actions :\n",
    "                x_centroid,y_centroid = state_centroid_dict[(row, col)]\n",
    "                if action == LEFT1:\n",
    "                    if self._pcn[row][col-1]== 1 and self._pcn[row][col+1]== 0.9:\n",
    "                        x_centroid +=dx[11]\n",
    "                        y_centroid +=(dy[11]-1)\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[11]\n",
    "                        y_centroid +=dy[11]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == LEFT2:\n",
    "                    if self._pcn[row][col-1]== 1 and self._pcn[row][col+1]== 0.9:\n",
    "                        x_centroid +=dx[2]\n",
    "                        y_centroid +=(dy[2]-1)\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target) \n",
    "                    else :\n",
    "                        x_centroid +=dx[2]\n",
    "                        y_centroid +=dy[2]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == LEFT3:\n",
    "                    if self._pcn[row][col-1]== 1 and self._pcn[row][col+1]== 0.9:\n",
    "                        x_centroid +=dx[7]\n",
    "                        y_centroid +=(dy[7]-1)\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[7]\n",
    "                        y_centroid +=dy[7]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == RIGHT1:\n",
    "                    if self._pcn[row][col+1]== 1 and self._pcn[row][col-1]== 0.9:\n",
    "                        x_centroid +=dx[5]\n",
    "                        y_centroid +=(dy[5]+1)\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[5]\n",
    "                        y_centroid +=dy[5]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == RIGHT2:\n",
    "                    if self._pcn[row][col+1]== 1 and self._pcn[row][col-1]== 0.9:\n",
    "                        x_centroid +=dx[0]\n",
    "                        y_centroid +=(dy[0]+1)\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[0]\n",
    "                        y_centroid +=dy[0]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == RIGHT3:\n",
    "                    if self._pcn[row][col+1]== 1 and self._pcn[row][col-1]== 0.9:\n",
    "                        x_centroid +=dx[9]\n",
    "                        y_centroid +=(dy[9]+1)\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[9]\n",
    "                        y_centroid +=dy[9]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == DOWN1:\n",
    "                    if self._pcn[row+1][col]== 1 and self._pcn[row-1][col]== 0.9:\n",
    "                        x_centroid +=(dx[10]+1)\n",
    "                        y_centroid +=dy[10]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[10]\n",
    "                        y_centroid +=dy[10]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == DOWN2:\n",
    "                    if self._pcn[row+1][col]== 1 and self._pcn[row-1][col]== 0.9:\n",
    "                        x_centroid +=(dx[1]+1)\n",
    "                        y_centroid +=dy[1]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[1]\n",
    "                        y_centroid +=dy[1]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == DOWN3:\n",
    "                    if self._pcn[row+1][col]== 1 and self._pcn[row-1][col]== 0.9:\n",
    "                        x_centroid +=(dx[6]+1)\n",
    "                        y_centroid +=dy[6]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[6]\n",
    "                        y_centroid +=dy[6]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == UP1:\n",
    "                    if self._pcn[row-1][col]== 1 and self._pcn[row+1][col]== 0.9:\n",
    "                        x_centroid +=(dx[4]-1)\n",
    "                        y_centroid +=dy[4]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[4]\n",
    "                        y_centroid +=dy[4]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == UP2:\n",
    "                    if self._pcn[row-1][col]== 1 and self._pcn[row+1][col]== 0.9:\n",
    "                        x_centroid +=(dx[3]-1)\n",
    "                        y_centroid +=dy[3]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[3]\n",
    "                        y_centroid +=dy[3]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == UP3:\n",
    "                    if self._pcn[row-1][col]== 1 and self._pcn[row+1][col]== 0.9:\n",
    "                        x_centroid +=(dx[8]-1)\n",
    "                        y_centroid +=dy[8]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[8]\n",
    "                        y_centroid +=dy[8]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                if (cur_distance<best_distance):\n",
    "                    best_distance = cur_distance\n",
    "                    best_choice = action\n",
    "                #print(\"Best distance : \",best_distance, \" Best choice : \",best_choice)\n",
    "            actions.clear()\n",
    "            actions.append(best_choice)\n",
    "        return actions\n",
    "    def check_valid_with_previous_state(self,cell):\n",
    "        row_cell, col_cell = cell\n",
    "        for temp in self.visited:\n",
    "            row, col = temp\n",
    "            if row_cell == row and col_cell == col :\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 117608,
     "status": "ok",
     "timestamp": 1593147108064,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "HYi1PiaNEwwH"
   },
   "outputs": [],
   "source": [
    "def show(qpcn):\n",
    "    plt.grid('on')\n",
    "    nrows, ncols = qpcn._pcn.shape\n",
    "    row_target,col_target = qpcn.target\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks(np.arange(0.5, nrows+20, 1))\n",
    "    ax.set_yticks(np.arange(0.5, ncols+20, 1))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    canvas = np.copy(qpcn._pcn)\n",
    "    for row,col in qpcn.visited:\n",
    "        canvas[row,col] = 0.7\n",
    "    agent_row, agent_col, _ = qpcn.state\n",
    "    canvas[agent_row, agent_col] = 0.3   # agent cell\n",
    "    canvas[row_target,col_target] = 0.2 # cheese cell\n",
    "    img = plt.imshow(canvas, interpolation='none', cmap='Reds_r')\n",
    "    plt.show()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 117596,
     "status": "ok",
     "timestamp": 1593147108066,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "aHUTI80rEw3-",
    "outputId": "b77175da-9b8f-46d7-a72d-2c9ce1f9a708",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2837c72a6a0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_width, img_height = pcn.shape\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_height, img_width)\n",
    "else:\n",
    "    input_shape = (img_height,img_width, 1)\n",
    "qpcn = Qpcn(pcn)\n",
    "qpcn.get_list_centroid()\n",
    "# canvas, reward, game_over = qpcn.act(DOWN)\n",
    "# print(\"reward=\", reward)\n",
    "show(qpcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 118292,
     "status": "ok",
     "timestamp": 1593147108772,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "jK31MzS0Ew_s",
    "outputId": "35750b8b-36fd-48cd-eb4d-185ad6e1b885"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x284a1c5ff10>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qpcn.act(LEFT1) \n",
    "#qpcn.act(RIGHT2)\n",
    "qpcn.act(DOWN3)  # move down\n",
    "qpcn.act(DOWN3)  # move right\n",
    "qpcn.act(RIGHT2)  # move right\n",
    "qpcn.act(DOWN3)  # move right\n",
    "qpcn.act(UP1)  # move up\n",
    "qpcn.act(DOWN3)  # move up\n",
    "qpcn.act(DOWN1)  # move up\n",
    "qpcn.act(DOWN1)  # move up\n",
    "show(qpcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x284a9868400>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qpcn.act(DOWN1)  # move up\n",
    "show(qpcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1539,
     "status": "ok",
     "timestamp": 1593149619964,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "uYXPeyapI47z"
   },
   "outputs": [],
   "source": [
    "def dist(x1,y1,x2,y2):\n",
    "        return ((x2-x1)**2 + (y2-y1)**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedTensorBoard(TensorBoard):\n",
    "\n",
    "    # Overriding init to set initial step and writer (we want one log file for all .fit() calls)\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.step = 1\n",
    "        self.writer = tf.compat.v1.summary.FileWriter(self.log_dir)\n",
    "\n",
    "    # Overriding this method to stop creating default log writer\n",
    "    def set_model(self, model):\n",
    "        pass\n",
    "\n",
    "    # Overrided, saves logs with our step number\n",
    "    # (otherwise every .fit() will start writing from 0th step)\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.update_stats(**logs)\n",
    "\n",
    "    # Overrided\n",
    "    # We train for one batch only, no need to save anything at epoch end\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        pass\n",
    "\n",
    "    # Overrided, so won't close writer\n",
    "    def on_train_end(self, _):\n",
    "        pass\n",
    "\n",
    "    # Custom method for saving own metrics\n",
    "    # Creates writer, writes custom metrics and closes writer\n",
    "    def update_stats(self, **stats):\n",
    "        self._write_logs(stats, self.step)\n",
    "\n",
    "    def _write_logs(self, logs, index):\n",
    "        self.writer.reopen()\n",
    "        for name, value in logs.items():\n",
    "            if name in ['batch', 'size']:\n",
    "                continue\n",
    "            summary = tf.compat.v1.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            if isinstance(value, np.ndarray):\n",
    "                summary_value.simple_value = value.item()\n",
    "            else:\n",
    "                summary_value.simple_value = value\n",
    "            summary_value.tag = name\n",
    "            self.writer.add_summary(summary, index)\n",
    "        self.writer.flush()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 941,
     "status": "ok",
     "timestamp": 1593149622607,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "VjXoRo7gE0Q0",
    "outputId": "2ddac579-f89a-41c4-8ab4-a096ab7b3fc4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode :  17  Probability :  [0.05861283 0.07805347 0.0984518  0.05895809 0.10981678 0.09742014\n",
      " 0.065192   0.09285127 0.10649988 0.0702467  0.10498815 0.05890892] \n",
      " Action :  7  Reward :  -0.03364182671684155  Loss :  -0.3364182671684155  Win count :  35\n",
      "Train on 128 samples\n",
      "Epoch 1/16\n",
      "128/128 [==============================] - 0s 179us/sample - loss: 0.8473\n",
      "Epoch 2/16\n",
      " 16/128 [==>...........................] - ETA: 0s - loss: 1.0855"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-1653a84dcdcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mold_action\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Episode : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" Probability : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpi_vec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\\n Action : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\" Reward : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\" Loss : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\" Win count : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwin_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[0mep_rewards\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward_sum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0mep_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_sum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Study\\RL\\RLAChips-V11\\agent.py\u001b[0m in \u001b[0;36mtrain_models\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;31m#Compute inputs for the optimizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mdiscounted_return\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madvantages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_advantages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmasks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;31m# print(discounted_return)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;31m# print(values)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pyLib-Gpu1.x\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m     return func.fit(\n\u001b[0m\u001b[0;32m    790\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pyLib-Gpu1.x\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    645\u001b[0m       \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m     return fit_loop(\n\u001b[0m\u001b[0;32m    648\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pyLib-Gpu1.x\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pyLib-Gpu1.x\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3954\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3956\u001b[1;33m     fetched = self._callable_fn(*array_vals,\n\u001b[0m\u001b[0;32m   3957\u001b[0m                                 run_metadata=self.run_metadata)\n\u001b[0;32m   3958\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pyLib-Gpu1.x\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1478\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1479\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1480\u001b[1;33m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[0;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1482\u001b[0m                                                run_metadata_ptr)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRAIN_ITEagentIONS = 50\n",
    "MAX_EPISODE_LENGTH = 128\n",
    "TRAJECtoRY_BUFFER_SIZE = 32\n",
    "BATCH_SIZE = 16\n",
    "RENDER_EVERY = 100\n",
    "AGGREGATE_STATS_EVERY = 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.chdir(\"D:/Study/RL/RLAChips-V11\")\n",
    "    img_height, img_width = pcn.shape\n",
    "    env = Qpcn(pcn)\n",
    "    EPISODES = 200000\n",
    "    k_permutation = 100\n",
    "    num_states = pcn.size\n",
    "    state_dim = env.state_dim\n",
    "    input_dim, output_dim = state_dim, num_actions\n",
    "    lr, gamma, loss_clipping, c1, lamda = 1e-6, 0.92 , 0.2, 0.001, 0.95\n",
    "    agent = Agent(input_dim, output_dim, lr, gamma, loss_clipping, c1,lamda,k_permutation)\n",
    "    tensorboard = ModifiedTensorBoard(log_dir=\"logs/{}-{}\".format(MODEL_NAME, int(time.time())))\n",
    "    MODEL_NAME = \"model\"\n",
    "    AGGREGATE_STATS_EVERY = 1\n",
    "    ep_rewards=[]\n",
    "    ep_loss = []\n",
    "    ep_pw = []\n",
    "    win_count = 0\n",
    "    num_non_cell = 30\n",
    "    supervision_factor = 0.3\n",
    "    for e in range(1,EPISODES+1):\n",
    "        agent_cell = random.choice(env.free_cells)\n",
    "        non_available_cell = random.choices(env.free_cells,k=num_non_cell)\n",
    "        target_cell = random.choice(env.free_target_cells)\n",
    "        #target_cell = random.choice(env.free_cells)\n",
    "        #target_cell = (34,33)\n",
    "        state = env.reset(agent_cell,target_cell,non_available_cell)\n",
    "#         for i in non_available_cell:\n",
    "#             print(i,env._pcn[i[0]][i[1]+1])\n",
    "#             time.sleep(2)\n",
    "        r_sum = 0\n",
    "        loss_sum =0 \n",
    "        reward_sum = 0\n",
    "        power_sum = 0\n",
    "        done = False\n",
    "        if e % 200==0:\n",
    "            clear_output(wait=True)\n",
    "        for cnt_step in range(MAX_EPISODE_LENGTH):\n",
    "#             show(env)\n",
    "#             time.sleep(0.5)\n",
    "            clear_output(wait=True)\n",
    "            #get action from agent given state\n",
    "            #print(state)\n",
    "            state = np.reshape(state,(-1,state_dim))\n",
    "            action,pi_vec =  agent.act(state)\n",
    "            ran_supervised = np.random.uniform(0,1)\n",
    "            if ran_supervised < supervision_factor:\n",
    "                env.supervised = 1\n",
    "                action = env.valid_actions()[0]\n",
    "                env.supervised = 0\n",
    "            #get s_,r,done\n",
    "            env.current_action = action\n",
    "            next_state, reward, done= env.act(action)\n",
    "            next_state = np.reshape(next_state,(-1,state_dim))\n",
    "            if cnt_step%1==0:\n",
    "                env.non_available_cell = random.choices(env.free_cells,k=num_non_cell)\n",
    "            reward_sum += reward\n",
    "            if done == 'not_over':\n",
    "                done = False\n",
    "            else :\n",
    "                done = True\n",
    "            mask = not done\n",
    "            agent.remember(state, action,mask,pi_vec, reward)\n",
    "            state = next_state\n",
    "            if done == True :\n",
    "                agent_cell = random.choice(env.free_cells)\n",
    "                non_available_cell = random.choices(env.free_cells,k=num_non_cell)\n",
    "                #target_cell = random.choice(env.free_target_cells)\n",
    "                target_cell = random.choice(env.free_cells)\n",
    "                #target_cell = (34,33)\n",
    "                state = env.reset(agent_cell,target_cell,non_available_cell)\n",
    "                loss_sum +=10*np.log10(3/4)\n",
    "                ep_rewards.append(reward_sum)\n",
    "                ep_loss.append(loss_sum)\n",
    "                ep_pw.append(power_sum)\n",
    "                loss_sum =0 \n",
    "                reward_sum = 0\n",
    "                power_sum = 0\n",
    "            if reward==2 :\n",
    "                loss = 0\n",
    "                win_count+=1\n",
    "            elif reward==0 :\n",
    "                loss = 0\n",
    "            elif reward == -1 :\n",
    "                loss = 0\n",
    "            elif reward == -1.5 :\n",
    "                try :\n",
    "                    loss = df[\"{}_to_{}\".format(action_node_dict[env.old_action],action_node_dict[env.current_action])]\n",
    "                except :\n",
    "                    loss = 0\n",
    "            else :\n",
    "                loss = reward\n",
    "            loss_sum+=loss*10\n",
    "            try :\n",
    "                power_sum += pc[\"{}_to_{}\".format(action_node_dict[env.old_action],action_node_dict[env.current_action])]\n",
    "            except :\n",
    "                power_sum +=0\n",
    "            env.old_action = action\n",
    "            print(\"Episode : \",e, \" Probability : \",pi_vec,\"\\n Action : \",action,\" Reward : \",reward,\" Loss : \",loss*10,\" Win count : \",win_count)\n",
    "        agent.train_models()\n",
    "        ep_rewards.append(reward_sum)\n",
    "        ep_loss.append(loss_sum)\n",
    "        ep_pw.append(power_sum)\n",
    "        if  e%AGGREGATE_STATS_EVERY==0 or e == 1 :\n",
    "            print(\"updating stats...\")\n",
    "            average_reward = sum(ep_rewards[-AGGREGATE_STATS_EVERY:]) / len(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "            min_reward = min(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "            max_reward = max(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "            average_loss = sum(ep_loss[-AGGREGATE_STATS_EVERY:]) / len(ep_loss[-AGGREGATE_STATS_EVERY:])\n",
    "            min_loss = min(ep_loss[-AGGREGATE_STATS_EVERY:])\n",
    "            max_loss = max(ep_loss[-AGGREGATE_STATS_EVERY:])\n",
    "            average_pwc = sum(ep_pw[-AGGREGATE_STATS_EVERY:]) / len(ep_pw[-AGGREGATE_STATS_EVERY:])\n",
    "            min_pwc = min(ep_loss[-AGGREGATE_STATS_EVERY:])\n",
    "            max_pwc = max(ep_loss[-AGGREGATE_STATS_EVERY:])\n",
    "            #tensorboard.update_stats(tranmission_loss=loss_sum)\n",
    "            tensorboard.step = e\n",
    "            tensorboard.update_stats(reward_avg=average_reward, reward_min=min_reward,\n",
    "                                           reward_max=max_reward,avarage_tranmission_loss = average_loss,\n",
    "                                           avarage_power_consumption = average_pwc,min_tranmission_loss = min_loss,\n",
    "                                           max_tranmission_loss = max_loss,min_power_consumption = min_pwc,\n",
    "                                           max_power_consumption = max_pwc,\n",
    "                                           epsilon=1)\n",
    "            agent.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ep_rewards = np.asarray(ep_rewards)\n",
    "result_ep_loss = np.asarray(ep_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 121119,
     "status": "aborted",
     "timestamp": 1593147111671,
     "user": {
      "displayName": "Nguyên Đỗ Hoàng Khôi",
      "photoUrl": "",
      "userId": "00234567357869733044"
     },
     "user_tz": -420
    },
    "id": "ybibrvVfcQiv"
   },
   "outputs": [],
   "source": [
    "rsl = pd.DataFrame(result_ep_loss)\n",
    "rsl.to_excel('rsl.xlsx', index=False, header=False)\n",
    "rsr = pd.DataFrame(result_ep_rewards)\n",
    "rsr.to_excel('rsr.xlsx', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedTensorBoard(TensorBoard):\n",
    "\n",
    "    # Overriding init to set initial step and writer (we want one log file for all .fit() calls)\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.step = 1\n",
    "        self.writer = tf.summary.create_file_writer(self.log_dir)\n",
    "\n",
    "    # Overriding this method to stop creating default log writer\n",
    "    def set_model(self, model):\n",
    "        pass\n",
    "\n",
    "    # Overrided, saves logs with our step number\n",
    "    # (otherwise every .fit() will start writing from 0th step)\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.update_stats(**logs)\n",
    "\n",
    "    # Overrided\n",
    "    # We train for one batch only, no need to save anything at epoch end\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        pass\n",
    "\n",
    "    # Overrided, so won't close writer\n",
    "    def on_train_end(self, _):\n",
    "        pass\n",
    "\n",
    "    # Custom method for saving own metrics\n",
    "    # Creates writer, writes custom metrics and closes writer\n",
    "    def update_stats(self, **stats):\n",
    "        self._write_logs(stats, self.step)\n",
    "\n",
    "    def _write_logs(self, stats, index):\n",
    "        #self.writer.reopen()\n",
    "        with self.writer.as_default():\n",
    "            tf.summary.scalar(name=\"reward_avg\",data=stats[\"reward_avg\"], step=self.step)\n",
    "            tf.summary.scalar(name=\"reward_min\",data=stats[\"reward_min\"], step=self.step)\n",
    "            tf.summary.scalar(name=\"reward_max\",data=stats[\"reward_max\"], step=self.step)\n",
    "            tf.summary.scalar(name=\"avarage_tranmission_loss\",data=stats[\"avarage_tranmission_loss\"], step=self.step)\n",
    "            tf.summary.scalar(name=\"avarage_power_consumption\",data=stats[\"avarage_power_consumption\"], step=self.step)\n",
    "            tf.summary.scalar(name=\"epsilon\",data=stats[\"reward_min\"], step=self.step)\n",
    "            self.writer.flush()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedTensorBoard(TensorBoard):\n",
    "\n",
    "    # Overriding init to set initial step and writer (we want one log file for all .fit() calls)\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.step = 1\n",
    "        #self.writer = tf.summary.FileWriter(self.log_dir)\n",
    "        self.writer = tf.summary.create_file_writer(self.log_dir)\n",
    "    # Overriding this method to stop creating default log writer\n",
    "    def set_model(self, model):\n",
    "        pass\n",
    "\n",
    "    # Overrided, saves logs with our step number\n",
    "    # (otherwise every .fit() will start writing from 0th step)\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.update_stats(**logs)\n",
    "\n",
    "    # Overrided\n",
    "    # We train for one batch only, no need to save anything at epoch end\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        pass\n",
    "\n",
    "    # Overrided, so won't close writer\n",
    "    def on_train_end(self, _):\n",
    "        pass\n",
    "\n",
    "    # Custom method for saving own metrics\n",
    "    # Creates writer, writes custom metrics and closes writer\n",
    "    def update_stats(self, **stats):\n",
    "        #self._write_logs(stats, self.step)\n",
    "        with self.writer.as_default():\n",
    "            tf.summary.scalar(name=\"reward_avg\",data=stats[\"reward_avg\"], step=self.step)\n",
    "            tf.summary.scalar(name=\"reward_min\",data=stats[\"reward_min\"], step=self.step)\n",
    "            tf.summary.scalar(name=\"reward_max\",data=stats[\"reward_max\"], step=self.step)\n",
    "            tf.summary.scalar(name=\"avarage_tranmission_loss\",data=stats[\"avarage_tranmission_loss\"], step=self.step)\n",
    "            tf.summary.scalar(name=\"avarage_power_consumption\",data=stats[\"avarage_power_consumption\"], step=self.step)\n",
    "            tf.summary.scalar(name=\"epsilon\",data=stats[\"reward_min\"], step=self.step)\n",
    "            self.writer.flush()\n",
    "\n",
    "    def _write_logs(self, logs, index):\n",
    "        self.writer.reopen()\n",
    "        for name, value in logs.items():\n",
    "            if name in ['batch', 'size']:\n",
    "                continue\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            if isinstance(value, np.ndarray):\n",
    "                summary_value.simple_value = value.item()\n",
    "            else:\n",
    "                summary_value.simple_value = value\n",
    "            summary_value.tag = name\n",
    "            #self.writer.add_summary(summary, index)\n",
    "            with self.writer.as_default():\n",
    "                tf.summary.scalar(name, summary, index)\n",
    "                self.writer.flush()\n",
    "        self.writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcn is a 2d Numpy array of floats between 0.0 to 1.0\n",
    "# 1.0 corresponds to a free cell, and 0.0 an occupied cell\n",
    "# agent = (row, col) initial agent position (defaults to (0,0))\n",
    "\n",
    "class Qpcn(object):\n",
    "    def __init__(self, pcn, agent=(0,1)):\n",
    "        self._pcn = np.array(pcn)\n",
    "        nrows, ncols = self._pcn.shape\n",
    "        self.target = (nrows-1,ncols-2) # target cell where the \"cheese\" is\n",
    "        self.free_cells = [(r,c) for r in range(nrows) for c in range(ncols) if self._pcn[r,c] == 1.0 ]\n",
    "        self.free_target_cells = []\n",
    "        for r in range(nrows):\n",
    "            for c in range(ncols):\n",
    "                if self._pcn[r,c] == 1.0 :\n",
    "                    if r == 0 or r == nrows-1 or c == 0 or c == ncols-1:\n",
    "                        self.free_target_cells.append((r,c))\n",
    "#                     if r == nrows-1 :\n",
    "#                         self.free_target_cells.append((r,c))\n",
    "        self.free_cells.remove(self.target)\n",
    "        self.current_distance = None\n",
    "        self.available_cell_target = []\n",
    "        self.centroid = []\n",
    "        self.supervised = 0\n",
    "        self.old_action = 1\n",
    "        self.current_action = None\n",
    "        self.num_non_available_cell = 0\n",
    "        self.state_dim = self.num_non_available_cell*2+4\n",
    "        if self._pcn[self.target] == 0.0:\n",
    "            raise Exception(\"Invalid pcn: target cell cannot be blocked!\")\n",
    "        if not agent in self.free_cells:\n",
    "            raise Exception(\"Invalid agent Location: must sit on a free cell\")\n",
    "        self.non_available_cell = random.choices(self.free_cells,k=self.num_non_available_cell)\n",
    "        self.reset(agent,self.target,self.non_available_cell)\n",
    "    def get_list_centroid(self):\n",
    "      dx=[0,2,0,-2,   -2,-1,2,1,    -2,1,2,-1]\n",
    "      dy=[2,0,-2,0,   -1,2,1,-2,    1,2,-1,-2]\n",
    "      for i in range (self._pcn.shape[0]):\n",
    "        for j in range (self._pcn.shape[1]):\n",
    "          if (self._pcn[i][j]==0.95) :\n",
    "            self.centroid.append((i,j))\n",
    "            for temp in range(12):\n",
    "              tx = i + dx[temp]\n",
    "              ty = j + dy[temp]\n",
    "              state_centroid_dict[(tx,ty)] = (i,j)\n",
    "    def available_cell_for_agent(self):\n",
    "        list_available_cell_agent = []\n",
    "        nrows, ncols = self._pcn.shape\n",
    "        for row in range(nrows) :\n",
    "            for col in range(ncols) :\n",
    "              if row == 1 or row == 2 or row == 3 or row ==6 or row == 7 or row ==8 or row == 11 or row == 12 or row == 13 :\n",
    "                if col == 0 or col == 14 :\n",
    "                      list_available_cell_agent.append((row,col))\n",
    "              if col== 1 or col == 2 or col == 3 or col ==6 or col == 7 or col ==8 or col == 11 or col == 12 or col == 13 :\n",
    "                if row == 0 or row == 14 :\n",
    "                      list_available_cell_agent.append((row,col))\n",
    "                if row == nrows-1 :\n",
    "                      self.available_cell_target.append((row,col))\n",
    "        return list_available_cell_agent\n",
    "    \n",
    "    def reset(self, agent,target,non_available_cell):\n",
    "        self.agent = agent\n",
    "        self._pcn = get_map()\n",
    "        nrows, ncols = self._pcn.shape\n",
    "        row, col = agent\n",
    "        self._pcn[row, col] = agent_mark\n",
    "        self.state = (row, col, 'valid')\n",
    "        self.min_reward = -256\n",
    "        self.total_reward = 0\n",
    "        self.visited = set()\n",
    "        self.target = target\n",
    "        target_row,target_col = self.target\n",
    "        self.old_distance = -999\n",
    "        self.list_previous_state=[]\n",
    "        self.non_available_cell = non_available_cell\n",
    "        return self.observe().reshape(1,self.state_dim)\n",
    "    \n",
    "    def check_state_centroid(self):\n",
    "        nrow, ncol, nmode = agent_row, agent_col, mode = self.state\n",
    "\n",
    "\n",
    "    def update_state(self, action):\n",
    "        nrows, ncols = self._pcn.shape\n",
    "        nrow, ncol, nmode = agent_row, agent_col, mode = self.state\n",
    "        if self._pcn[agent_row, agent_col] > 0:\n",
    "            self.visited.add((agent_row, agent_col))  # mark visited cell\n",
    "\n",
    "        valid_actions = self.valid_actions()\n",
    "        x_centroid,y_centroid = state_centroid_dict[(nrow, ncol)]\n",
    "        if not valid_actions:\n",
    "            nmode = 'blocked'\n",
    "        elif action in valid_actions:\n",
    "            nmode = 'valid'\n",
    "            dx=[0,2,0,-2,   -2,-1,2,1,    -2,1,2,-1]\n",
    "            dy=[2,0,-2,0,   -1,2,1,-2,    1,2,-1,-2]\n",
    "            #r2,d2,l2,u2,u1,r1,d3,l3,u3,r3,d1,l1\n",
    "            #0 ,1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10 ,11\n",
    "            if action == LEFT1:\n",
    "              if self._pcn[nrow][ncol-1]== 1 and self._pcn[nrow][ncol+1]== 0.9:\n",
    "                x_centroid +=dx[11]\n",
    "                y_centroid +=(dy[11]-1)\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[11]\n",
    "                y_centroid +=dy[11]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == LEFT2:\n",
    "              if self._pcn[nrow][ncol-1]== 1 and self._pcn[nrow][ncol+1]== 0.9:\n",
    "                x_centroid +=dx[2]\n",
    "                y_centroid +=(dy[2]-1)\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[2]\n",
    "                y_centroid +=dy[2]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == LEFT3:\n",
    "              if self._pcn[nrow][ncol-1]== 1 and self._pcn[nrow][ncol+1]== 0.9:\n",
    "                x_centroid +=dx[7]\n",
    "                y_centroid +=(dy[7]-1)\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[7]\n",
    "                y_centroid +=dy[7]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == RIGHT1:\n",
    "              if self._pcn[nrow][ncol+1]== 1 and self._pcn[nrow][ncol-1]== 0.9:\n",
    "                x_centroid +=dx[5]\n",
    "                y_centroid +=(dy[5]+1)\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[5]\n",
    "                y_centroid +=dy[5]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == RIGHT2:\n",
    "              if self._pcn[nrow][ncol+1]== 1 and self._pcn[nrow][ncol-1]== 0.9:\n",
    "                x_centroid +=dx[0]\n",
    "                y_centroid +=(dy[0]+1)\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[0]\n",
    "                y_centroid +=dy[0]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == RIGHT3:\n",
    "              if self._pcn[nrow][ncol+1]== 1 and self._pcn[nrow][ncol-1]== 0.9:\n",
    "                x_centroid +=dx[9]\n",
    "                y_centroid +=(dy[9]+1)\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[9]\n",
    "                y_centroid +=dy[9]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == DOWN1:\n",
    "              if self._pcn[nrow+1][ncol]== 1 and self._pcn[nrow-1][ncol]== 0.9:\n",
    "                x_centroid +=(dx[10]+1)\n",
    "                y_centroid +=dy[10]\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[10]\n",
    "                y_centroid +=dy[10]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == DOWN2:\n",
    "              if self._pcn[nrow+1][ncol]== 1 and self._pcn[nrow-1][ncol]== 0.9:\n",
    "                x_centroid +=(dx[1]+1)\n",
    "                y_centroid +=dy[1]\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[1]\n",
    "                y_centroid +=dy[1]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == DOWN3:\n",
    "              if self._pcn[nrow+1][ncol]== 1 and self._pcn[nrow-1][ncol]== 0.9:\n",
    "                x_centroid +=(dx[6]+1)\n",
    "                y_centroid +=dy[6]\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[6]\n",
    "                y_centroid +=dy[6]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == UP1:\n",
    "              if self._pcn[nrow-1][ncol]== 1 and self._pcn[nrow+1][ncol]== 0.9:\n",
    "                x_centroid +=(dx[4]-1)\n",
    "                y_centroid +=dy[4]\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[4]\n",
    "                y_centroid +=dy[4]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == UP2:\n",
    "              if self._pcn[nrow-1][ncol]== 1 and self._pcn[nrow+1][ncol]== 0.9:\n",
    "                x_centroid +=(dx[3]-1)\n",
    "                y_centroid +=dy[3]\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[3]\n",
    "                y_centroid +=dy[3]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "            elif action == UP3:\n",
    "              if self._pcn[nrow-1][ncol]== 1 and self._pcn[nrow+1][ncol]== 0.9:\n",
    "                x_centroid +=(dx[8]-1)\n",
    "                y_centroid +=dy[8]\n",
    "                nmode = 'reward_unchanged'\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "              else :\n",
    "                x_centroid +=dx[8]\n",
    "                y_centroid +=dy[8]\n",
    "                if self._pcn[x_centroid,y_centroid]==0.0 :\n",
    "                    nmode = 'blocked'\n",
    "                else :\n",
    "                    self.state = (x_centroid,y_centroid, nmode)\n",
    "        else:                  # invalid action, no change in agent position\n",
    "            #nmode = 'invalid'\n",
    "            pass\n",
    "\n",
    "    def get_reward(self):\n",
    "        agent_row, agent_col, mode = self.state\n",
    "        target_row,target_col = self.target\n",
    "        nrows, ncols = self._pcn.shape\n",
    "        reward = None\n",
    "        status = None\n",
    "        if mode == 'reward_unchanged'and not (agent_row, agent_col) in self.visited:\n",
    "          #mode = \"valid\"\n",
    "          return 0\n",
    "#         if self.current_action == self.old_action :\n",
    "#           return -1.2\n",
    "        if mode == 'blocked':\n",
    "            reward  =self.min_reward - 0.5\n",
    "        if (agent_row, agent_col) in self.visited:\n",
    "            return -1.5\n",
    "        if mode == 'invalid':\n",
    "            reward  = -2\n",
    "        # if mode == 'valid':\n",
    "        #     reward  = -0.04\n",
    "        if mode == 'valid':\n",
    "            # self.current_distance = self.dist(agent_row,agent_col,target_row,target_col)\n",
    "            # if self.current_distance <= self.old_distance :\n",
    "            #       reward = -self.current_distance*0.004\n",
    "                  \n",
    "            # else : reward = -self.current_distance*0.005\n",
    "            # self.old_distance = self.current_distance\n",
    "            try : \n",
    "              reward = df[\"{}_to_{}\".format(action_node_dict[self.old_action],action_node_dict[self.current_action])]\n",
    "            except :\n",
    "              reward = -1\n",
    "        if agent_row == target_row and agent_col == target_col:\n",
    "            status = 'win'\n",
    "            return 2\n",
    "        # if mode == 'valid' and status !='win':\n",
    "        #       self.current_distance = self.dist(agent_row,agent_col,target_row,target_col)\n",
    "        #       if (agent_row, agent_col) in self.visited :\n",
    "        #           reward = -0.25\n",
    "        #       elif self.current_distance >= self.old_distance :\n",
    "        #       #reward = -current_distance*0.001\n",
    "        #           reward = -0.1             \n",
    "        #       else : reward = -0.04\n",
    "        #       self.old_distance = self.current_distance\n",
    "        return reward\n",
    "    def dist(self,x1,y1,x2,y2):\n",
    "        return ((x2-x1)**2 + (y2-y1)**2)**0.5\n",
    "    def act(self, action):\n",
    "        self.update_state(action)\n",
    "        reward = self.get_reward()\n",
    "        self.total_reward += reward\n",
    "        status = self.game_status()\n",
    "        envstate = self.observe()\n",
    "        return envstate, reward, status\n",
    "    def act_to_predict(self, action):\n",
    "        self.update_state_to_predict(action)\n",
    "        status = self.game_status_to_predict()\n",
    "        envstate = self.observe()\n",
    "        return envstate, status\n",
    "\n",
    "    def observe(self):\n",
    "        canvas = self.draw_env(self.non_available_cell)\n",
    "        envstate = np.reshape(canvas,newshape=(1,self.state_dim))\n",
    "        return envstate\n",
    "\n",
    "    def draw_env(self, non_available_cell):\n",
    "        self._pcn = get_map()\n",
    "        row, col = self.agent\n",
    "        self._pcn[row, col] = agent_mark\n",
    "        canvas = np.copy(self._pcn)\n",
    "        nrows, ncols = self._pcn.shape\n",
    "        # clear all visual marks\n",
    "        for r in range(nrows):\n",
    "            for c in range(ncols):\n",
    "                if canvas[r,c] > 0.0:\n",
    "                    canvas[r,c] = 1.0\n",
    "                if (r,c) in  non_available_cell:\n",
    "                    canvas[r,c] = 0.0\n",
    "                    self._pcn[r,c]= 0.0\n",
    "        # draw the agent\n",
    "        for row,col in self.visited:\n",
    "            canvas[row,col] = 0.6\n",
    "        row, col, valid = self.state\n",
    "        row_target,col_target =  self.target\n",
    "        canvas[row, col] = agent_mark\n",
    "        canvas[row_target,col_target] = target_mark\n",
    "        #canvas = noisy(\"gauss\",canvas)\n",
    "        input_state = [row,col,row_target,col_target]\n",
    "        for item in non_available_cell:\n",
    "            input_state.append(item[0])\n",
    "            input_state.append(item[1])\n",
    "        input_state = np.asarray(input_state).reshape(-1, 1)\n",
    "        std_scale = preprocessing.StandardScaler().fit(input_state)\n",
    "        input_state = std_scale.transform(input_state)\n",
    "        return input_state\n",
    "\n",
    "    def game_status(self):\n",
    "        if self.total_reward < self.min_reward:\n",
    "            return 'lose'\n",
    "        agent_row, agent_col, mode = self.state\n",
    "        nrows, ncols = self._pcn.shape\n",
    "        target_row,target_col = self.target\n",
    "        if agent_row == target_row and agent_col == target_col:\n",
    "            return 'win'\n",
    "\n",
    "        return 'not_over'\n",
    "    def set_supervised(self,supervised):\n",
    "        self.supervised = supervised \n",
    "    def game_status_to_predict(self):\n",
    "        agent_row, agent_col, mode = self.state\n",
    "        target_row,target_col = self.target\n",
    "        if agent_row == target_row and agent_col == target_col:\n",
    "            return 'win'\n",
    "\n",
    "        return 'not_over'\n",
    "\n",
    "    def valid_actions(self, cell=None):\n",
    "        if cell is None:\n",
    "            row, col, mode = self.state\n",
    "        else:\n",
    "            row, col = cell\n",
    "        actions = [LEFT1, LEFT2, LEFT3, RIGHT1, RIGHT2, RIGHT3, UP1, UP2, UP3, DOWN1, DOWN2, DOWN3]\n",
    "        nrows, ncols = self._pcn.shape\n",
    "        if row == 0:\n",
    "            actions.remove(UP1)\n",
    "            actions.remove(UP2)\n",
    "            actions.remove(UP3)\n",
    "        elif row == nrows-1:\n",
    "            actions.remove(DOWN1)\n",
    "            actions.remove(DOWN2)\n",
    "            actions.remove(DOWN3)\n",
    "        if col == 0:\n",
    "            actions.remove(LEFT1)\n",
    "            actions.remove(LEFT2)\n",
    "            actions.remove(LEFT3)\n",
    "        elif col == ncols-1:\n",
    "            actions.remove(RIGHT1)\n",
    "            actions.remove(RIGHT2)\n",
    "            actions.remove(RIGHT3)\n",
    "        # if row>0 and self.pcn[row-1,col] == 0.0:\n",
    "        #     actions.remove(UP1)\n",
    "        #     actions.remove(UP2)\n",
    "        #     actions.remove(UP3)\n",
    "        #     actions.remove(UP4)\n",
    "        # if row<nrows-1 and self.pcn[row+1,col] == 0.0:\n",
    "        #     actions.remove(DOWN1)\n",
    "        #     actions.remove(DOWN2)\n",
    "        #     actions.remove(DOWN3)\n",
    "        #     actions.remove(DOWN4)\n",
    "        # if col>0 and self.pcn[row,col-1] == 0.0:\n",
    "        #     actions.remove(LEFT1)\n",
    "        #     actions.remove(LEFT2)\n",
    "        #     actions.remove(LEFT3)\n",
    "        #     actions.remove(LEFT4)\n",
    "        # if col<ncols-1 and self.pcn[row,col+1] == 0.0:\n",
    "        #     actions.remove(RIGHT1)\n",
    "        #     actions.remove(RIGHT2)\n",
    "        #     actions.remove(RIGHT3)\n",
    "        #     actions.remove(RIGHT4)\n",
    "        dx=[0,2,0,-2,   -2,-1,2,1,    -2,1,2,-1]\n",
    "        dy=[2,0,-2,0,   -1,2,1,-2,    1,2,-1,-2]\n",
    "        #r2,d2,l2,u2,u1,r1,d3,l3,u3,r3,d1,l1\n",
    "        #0 ,1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10 ,11\n",
    "        tx_target,ty_target = self.target\n",
    "        if self.supervised == 1:\n",
    "            best_choice = None\n",
    "            best_distance = 999999\n",
    "            for action in actions :\n",
    "                x_centroid,y_centroid = state_centroid_dict[(row, col)]\n",
    "                if action == LEFT1:\n",
    "                    if self._pcn[row][col-1]== 1 and self._pcn[row][col+1]== 0.9:\n",
    "                        x_centroid +=dx[11]\n",
    "                        y_centroid +=(dy[11]-1)\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[11]\n",
    "                        y_centroid +=dy[11]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == LEFT2:\n",
    "                    if self._pcn[row][col-1]== 1 and self._pcn[row][col+1]== 0.9:\n",
    "                        x_centroid +=dx[2]\n",
    "                        y_centroid +=(dy[2]-1)\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target) \n",
    "                    else :\n",
    "                        x_centroid +=dx[2]\n",
    "                        y_centroid +=dy[2]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == LEFT3:\n",
    "                    if self._pcn[row][col-1]== 1 and self._pcn[row][col+1]== 0.9:\n",
    "                        x_centroid +=dx[7]\n",
    "                        y_centroid +=(dy[7]-1)\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[7]\n",
    "                        y_centroid +=dy[7]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == RIGHT1:\n",
    "                    if self._pcn[row][col+1]== 1 and self._pcn[row][col-1]== 0.9:\n",
    "                        x_centroid +=dx[5]\n",
    "                        y_centroid +=(dy[5]+1)\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[5]\n",
    "                        y_centroid +=dy[5]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == RIGHT2:\n",
    "                    if self._pcn[row][col+1]== 1 and self._pcn[row][col-1]== 0.9:\n",
    "                        x_centroid +=dx[0]\n",
    "                        y_centroid +=(dy[0]+1)\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[0]\n",
    "                        y_centroid +=dy[0]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == RIGHT3:\n",
    "                    if self._pcn[row][col+1]== 1 and self._pcn[row][col-1]== 0.9:\n",
    "                        x_centroid +=dx[9]\n",
    "                        y_centroid +=(dy[9]+1)\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[9]\n",
    "                        y_centroid +=dy[9]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == DOWN1:\n",
    "                    if self._pcn[row+1][col]== 1 and self._pcn[row-1][col]== 0.9:\n",
    "                        x_centroid +=(dx[10]+1)\n",
    "                        y_centroid +=dy[10]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[10]\n",
    "                        y_centroid +=dy[10]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == DOWN2:\n",
    "                    if self._pcn[row+1][col]== 1 and self._pcn[row-1][col]== 0.9:\n",
    "                        x_centroid +=(dx[1]+1)\n",
    "                        y_centroid +=dy[1]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[1]\n",
    "                        y_centroid +=dy[1]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == DOWN3:\n",
    "                    if self._pcn[row+1][col]== 1 and self._pcn[row-1][col]== 0.9:\n",
    "                        x_centroid +=(dx[6]+1)\n",
    "                        y_centroid +=dy[6]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[6]\n",
    "                        y_centroid +=dy[6]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == UP1:\n",
    "                    if self._pcn[row-1][col]== 1 and self._pcn[row+1][col]== 0.9:\n",
    "                        x_centroid +=(dx[4]-1)\n",
    "                        y_centroid +=dy[4]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[4]\n",
    "                        y_centroid +=dy[4]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == UP2:\n",
    "                    if self._pcn[row-1][col]== 1 and self._pcn[row+1][col]== 0.9:\n",
    "                        x_centroid +=(dx[3]-1)\n",
    "                        y_centroid +=dy[3]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[3]\n",
    "                        y_centroid +=dy[3]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                elif action == UP3:\n",
    "                    if self._pcn[row-1][col]== 1 and self._pcn[row+1][col]== 0.9:\n",
    "                        x_centroid +=(dx[8]-1)\n",
    "                        y_centroid +=dy[8]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    else :\n",
    "                        x_centroid +=dx[8]\n",
    "                        y_centroid +=dy[8]\n",
    "                        cur_distance = self.dist(x_centroid,y_centroid,tx_target,ty_target)\n",
    "                    if self._pcn[x_centroid][y_centroid]==0:\n",
    "                        cur_distance = 9999\n",
    "                if (cur_distance<best_distance):\n",
    "                    best_distance = cur_distance\n",
    "                    best_choice = action\n",
    "                #print(\"Best distance : \",best_distance, \" Best choice : \",best_choice)\n",
    "            actions.clear()\n",
    "            actions.append(best_choice)\n",
    "        return actions\n",
    "    def check_valid_with_previous_state(self,cell):\n",
    "        row_cell, col_cell = cell\n",
    "        for temp in self.visited:\n",
    "            row, col = temp\n",
    "            if row_cell == row and col_cell == col :\n",
    "                return False\n",
    "        return True"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyOslRe9iSuuIZbBBqNQE42x",
   "collapsed_sections": [],
   "name": "Bản sao của RLAChip.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
